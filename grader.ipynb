{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these after removing hastag if any on of the given module is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hastag if having problem with gensim\n",
    "import sys\n",
    "\n",
    "#!$sys.executable -m pip install keras\n",
    "#!$sys.executable -m pip install nltk\n",
    "import nltk\n",
    "\n",
    "#!$sys.executable -m pip install gensim\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#!$sys.executable -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR=\"Dataset and discription/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(columns=['rater1_domain1','rater2_domain1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  \n",
       "0                  8  \n",
       "1                  9  \n",
       "2                  7  \n",
       "3                 10  \n",
       "4                  8  \n",
       "...              ...  \n",
       "12971             35  \n",
       "12972             32  \n",
       "12973             40  \n",
       "12974             40  \n",
       "12975             40  \n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=X['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
    "maximum_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  score  \n",
       "0                  8    6.0  \n",
       "1                  9    7.0  \n",
       "2                  7    5.0  \n",
       "3                 10    8.0  \n",
       "4                  8    6.0  \n",
       "...              ...    ...  \n",
       "12971             35    6.0  \n",
       "12972             32    5.0  \n",
       "12973             40    7.0  \n",
       "12974             40    7.0  \n",
       "12975             40    7.0  \n",
       "\n",
       "[12976 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_min = minimum_scores[X['essay_set']]\n",
    "old_max = maximum_scores[X['essay_set']]\n",
    "old_range = old_max - old_min \n",
    "new_range = (10 - 0)  \n",
    "X['score'] = np.around((((X['domain1_score'] - old_min) * new_range) / old_range) )\n",
    "\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokanization and vectorization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "def wordlist(essay, remove_stopwords):\n",
    "    \n",
    "    essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
    "    words = essay.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_sentences(essay, remove_stopwords):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    \n",
    "    featureVec = np.zeros((num_features),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of pre processing , tokanization then vectorivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of tokanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function'], ['tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega'], ['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function', 'tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega'], ['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function'], ['tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "example2='hi I am an example1 sentence here to explain thw working of above function .Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "example1='hi I am an example22 sentence here to explain thw working of above function. Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "example3='hi I am an example33 sentence here to explain thw working of above function. Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "s=[]\n",
    "s +=Make_sentences(example1,remove_stopwords=True)\n",
    "s +=Make_sentences(example2,remove_stopwords=True)\n",
    "s +=Make_sentences(example3,remove_stopwords=True)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=15, vector_size=100, alpha=0.025)\n",
      "['jayega', 'aa', 'samajh', 'isecay', 'shayad', 'hai', 'pakhandi', 'tiwari', 'function', 'working', 'thw', 'explain', 'sentence', 'example', 'hi']\n",
      "[ 7.6937797e-03  9.1159474e-03  1.1371024e-03 -8.3266143e-03\n",
      "  8.4234700e-03 -3.6967925e-03  5.7412465e-03  4.3951930e-03\n",
      "  9.6916147e-03 -9.2963111e-03  9.2080925e-03 -9.2849806e-03\n",
      " -6.9090333e-03 -9.1020577e-03 -5.5503827e-03  7.3705087e-03\n",
      "  9.1668312e-03 -3.3259962e-03  3.7265129e-03 -3.6276821e-03\n",
      "  7.8818426e-03  5.8701234e-03  3.1563587e-07 -3.6258488e-03\n",
      " -7.2205034e-03  4.7711711e-03  1.4503270e-03 -2.6101116e-03\n",
      "  7.8361779e-03 -4.0486371e-03 -9.1493567e-03 -2.2525082e-03\n",
      "  1.2837682e-04 -6.6368566e-03 -5.4893969e-03 -8.5005304e-03\n",
      "  9.2295222e-03  7.4223373e-03 -2.9353739e-04  7.3695402e-03\n",
      "  7.9519944e-03 -7.7969249e-04  6.6087437e-03  3.7650829e-03\n",
      "  5.0741732e-03  7.2507611e-03 -4.7409856e-03 -2.1847258e-03\n",
      "  8.7262300e-04  4.2386064e-03  3.3045979e-03  5.0974917e-03\n",
      "  4.5837699e-03 -8.4385853e-03 -3.1799104e-03 -7.2401213e-03\n",
      "  9.6792430e-03  5.0045145e-03  1.7498615e-04  4.1163173e-03\n",
      " -7.6607405e-03 -6.2946621e-03  3.0802120e-03  6.5347711e-03\n",
      "  3.9474918e-03  6.0163550e-03 -1.9876563e-03 -3.3497475e-03\n",
      "  2.0709650e-04 -3.1957270e-03 -5.5131125e-03 -7.7857119e-03\n",
      "  6.5343911e-03 -1.0947213e-03 -1.8904419e-03 -7.8064846e-03\n",
      "  9.3418444e-03  8.6251087e-04  1.7692363e-03  2.4927426e-03\n",
      " -7.3862029e-03  1.6389518e-03  2.9787791e-03 -8.5606640e-03\n",
      "  4.9517085e-03  2.4325817e-03  7.4991216e-03  5.0448528e-03\n",
      " -3.0327144e-03 -7.1612983e-03  7.0947898e-03  1.9038507e-03\n",
      "  5.2038110e-03  6.3810335e-03  1.9142814e-03 -6.1276453e-03\n",
      " -4.5204279e-06  8.2704099e-03 -6.0930839e-03  9.4411215e-03]\n",
      "Word2Vec(vocab=15, vector_size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(s, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.index_to_key )\n",
    "print(words)\n",
    "# access vector for one word\n",
    "print(model.wv['hi'])\n",
    "# save model\n",
    "model.save('model.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto the real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "skf = KFold(n_splits=5,shuffle=True)\n",
    "count=1\n",
    "results=[]\n",
    "y_pred_list = []\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, Y_train, y_test = train_test_split(X,Y, test_size=0.33, shuffle= True)\n",
    "\n",
    "trainE = X_train['essay']\n",
    "testE= X_test['essay']\n",
    "sentences=[]\n",
    "for essay in trainE:\n",
    "        # Obtaining all sentences from the training essays.    \n",
    "    sentences +=Make_sentences(essay, remove_stopwords = True)\n",
    "        \n",
    "        #Initializing different parameters for the word2vec model to be used\n",
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "print(\"Training Word2Vec Model...\")\n",
    "        \n",
    "#Initializing model fro vectorization\n",
    "        \n",
    "    \n",
    "        #initializing model and loading parameters\n",
    "    \n",
    "model = Word2Vec(sentences,vector_size=300, workers=num_workers, min_count = min_word_count, window = context)\n",
    "        #avoiding normalization to not reduce the essence of some words used in context\n",
    "    \n",
    "model.init_sims(replace=True)\n",
    "    \n",
    "        #saving model\n",
    "    \n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "clean_train = []\n",
    "\n",
    "for essay in trainE:\n",
    "    clean_train.append(wordlist(essay, remove_stopwords=True))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs(clean_train, model, num_features)  \n",
    "\n",
    "clean_test = []\n",
    "for essay in testE:\n",
    "    clean_test.append(wordlist(essay, remove_stopwords=True))\n",
    "                                      \n",
    "testDataVecs = getAvgFeatureVecs(clean_test, model, num_features)\n",
    "trainDataVecs = np.array(trainDataVecs)\n",
    "testDataVecs = np.array(testDataVecs)\n",
    "trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))        \n",
    "    \n",
    "lstm_model = get_model()\n",
    "        \n",
    "        \n",
    "        \n",
    "history=lstm_model.fit(trainDataVecs, Y_train, batch_size=64, epochs=50,validation_split=0.1)\n",
    "if count == 5:\n",
    "    lstm_model.save('./finalnew_lstm.h5')\n",
    "    \n",
    "        \n",
    "       \n",
    "        \n",
    "y_pred = lstm_model.predict(testDataVecs)\n",
    "        \n",
    "    \n",
    "y_pred = np.around(y_pred)\n",
    "y_pred_list.append(y_pred)\n",
    "            \n",
    "result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "print(\"Kappa Score: {}\".format(result))\n",
    "results.append(result)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a78f4367b08b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "sentences.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxYUlEQVR4nO3deXhV1bn48e97zklyyBxCgkHAgIaZJGC0VCyDqBUncKatFW2trdZW22srequovd5Lb6lVW7U/tFq1VqUq6lXrwCS1UhQQEAREkCECIQQyz+es3x9rZyRkIieHZL+f59nPPmefPawd9N17v2vttcQYg1JKKffwhLsASimlupcGfqWUchkN/Eop5TIa+JVSymU08CullMv4wl2A9ujXr59JT08PdzGUUqpHWbNmzUFjTErz5T0i8Kenp7N69epwF0MppXoUEdnV0nJN9SillMto4FdKKZfRwK+UUi7TI3L8SqnuV1NTQ25uLpWVleEuimqD3+9n4MCBREREtGt9DfxKqRbl5uYSFxdHeno6IhLu4qijMMZQUFBAbm4uQ4YMadc2mupRSrWosrKS5ORkDfrHOREhOTm5Q09mGviVUkelQb9n6Oi/U+8O/G+8AfPmhbsUSil1XOndgf/dd+E3vwl3KZRSnVBYWMijjz7aqW3PP/98CgsLW13n7rvvZvHixZ3af3Pp6ekcPHiwS/bVHXp34E9MhKIiCAbDXRKlVAe1FvgDgUCr27711lskJia2us59993H2Wef3dni9Wi9P/AbAyUl4S6JUqqD5syZw/bt28nOzuYXv/gFy5cvZ+rUqXz7299m7NixAMycOZNTTz2V0aNHs2DBgvpt6+7Ad+7cyciRI/nBD37A6NGjOffcc6moqADg2muv5aWXXqpff+7cuYwfP56xY8eyZcsWAPLz8znnnHMYP348P/zhDznppJPavLN/4IEHGDNmDGPGjOHBBx8EoKysjAsuuICsrCzGjBnDiy++WH+Oo0aNIjMzk9tuu61L/36t6d3NOeuu+EVFkJAQ1qIo1aPdeiusW9e1+8zOBicwtmTevHls3LiRdc5xly9fzkcffcTGjRvrmy0++eST9O3bl4qKCk477TQuu+wykpOTm+xn27ZtPP/88zz++ONceeWVvPzyy1x99dVHHK9fv36sXbuWRx99lPnz5/PEE09w7733ctZZZ3HHHXfw9ttvN7m4tGTNmjU89dRTrFq1CmMMX/va15g8eTI7duxgwIABvPnmmwAUFRVx6NAhFi1axJYtWxCRNlNTXal33/HXBftu/IMqpULn9NNPb9JW/eGHHyYrK4sJEyawZ88etm3bdsQ2Q4YMITs7G4BTTz2VnTt3trjvSy+99Ih1PvjgA2bNmgXAeeedR1JSUqvl++CDD7jkkkuIiYkhNjaWSy+9lH/+85+MHTuWxYsXc/vtt/PPf/6ThIQE4uPj8fv9XH/99bzyyitER0d38K/Ree6449fAr9SxaeXOvDvFxMTUf16+fDmLFy9m5cqVREdHM2XKlBbbskdFRdV/9nq99ameo63n9Xqpra0F7MtRHXG09YcNG8aaNWt46623uOOOOzj33HO5++67+eijj1iyZAkvvPACf/zjH1m6dGmHjtdZvfuOv3GqRynVo8TFxVHSSv1cUVERSUlJREdHs2XLFv797393eRnOPPNMFi5cCMC7777L4cOHW11/0qRJvPrqq5SXl1NWVsaiRYv4xje+wd69e4mOjubqq6/mtttuY+3atZSWllJUVMT555/Pgw8+WJ/S6g69+45fUz1K9VjJyclMnDiRMWPGMH36dC644IImv5933nn86U9/IjMzk+HDhzNhwoQuL8PcuXP51re+xYsvvsjkyZNJS0sjLi7uqOuPHz+ea6+9ltNPPx2A66+/nnHjxvHOO+/wi1/8Ao/HQ0REBI899hglJSXMmDGDyspKjDH8/ve/7/LyH4109FEmHHJyckynBmI5eBBSUuDhh+EnP+n6ginVi23evJmRI0eGuxhhVVVVhdfrxefzsXLlSm688cZuvTPviJb+vURkjTEmp/m67rjj11SPUqoTdu/ezZVXXkkwGCQyMpLHH3883EXqEr078EdEQHS0pnqUUp2SkZHBJ598Eu5idLneXbkLtoJXA79SStXTwK+UUi7jjsCvOX6llKoXssAvIsNFZF2jqVhEbhWRviLynohsc+atvwp3rBIS9I5fKaUaCVngN8ZsNcZkG2OygVOBcmARMAdYYozJAJY430NHUz1KuUZsbCwAe/fu5fLLL29xnSlTptBW8/AHH3yQ8vLy+u/t6ea5Pe655x7mz59/zPs5Vt2V6pkGbDfG7AJmAE87y58GZob0yJrqUcp1BgwYUN/zZmc0D/zt6ea5J+muwD8LeN753N8Ysw/Amae2tIGI3CAiq0VkdX5+fuePXJfq6QEvqimlGtx+++1N+uO/5557+N3vfkdpaSnTpk2r70L5tddeO2LbnTt3MmbMGAAqKiqYNWsWmZmZXHXVVU366rnxxhvJyclh9OjRzJ07F7Adv+3du5epU6cydepUoOlAKy11u9xa989Hs27dOiZMmEBmZiaXXHJJfXcQDz/8cH1XzXUdxL3//vtkZ2eTnZ3NuHHjWu3Koj1C3o5fRCKBi4E7OrKdMWYBsADsm7udLkBiItTUQEWFbdOvlOqwe/9vE5/tLe7SfY4aEM/ci0Yf9fdZs2Zx6623ctNNNwGwcOFC3n77bfx+P4sWLSI+Pp6DBw8yYcIELr744qOOO/vYY48RHR3Nhg0b2LBhA+PHj6//7f7776dv374EAgGmTZvGhg0b+OlPf8oDDzzAsmXL6NevX5N9Ha3b5aSkpHZ3/1znmmuu4Q9/+AOTJ0/m7rvv5t577+XBBx9k3rx5fPnll0RFRdWnl+bPn88jjzzCxIkTKS0txe/3t/fP3KLuuOOfDqw1xuQ53/NEJA3AmR8I6dG1ozaleqRx48Zx4MAB9u7dy/r160lKSmLw4MEYY7jzzjvJzMzk7LPP5quvviIvL++o+1mxYkV9AM7MzCQzM7P+t4ULFzJ+/HjGjRvHpk2b+Oyzz1ot09G6XYb2d/8MtoO5wsJCJk+eDMDs2bNZsWJFfRm/853v8Ne//hWfz96bT5w4kZ///Oc8/PDDFBYW1i/vrO54c/dbNKR5AF4HZgPznPmRz2ldqXFHbWlpIT2UUr1Va3fmoXT55Zfz0ksvsX///vq0x3PPPUd+fj5r1qwhIiKC9PT0Frtjbqylp4Evv/yS+fPn8/HHH5OUlMS1117b5n5a69usvd0/t+XNN99kxYoVvP766/z6179m06ZNzJkzhwsuuIC33nqLCRMmsHjxYkaMGNGp/UOI7/hFJBo4B3il0eJ5wDkiss35bV4oy6B98ivVc82aNYsXXniBl156qb6VTlFREampqURERLBs2TJ27drV6j4mTZrEc889B8DGjRvZsGEDAMXFxcTExJCQkEBeXh7/+Mc/6rc5WpfQR+t2uaMSEhJISkqqf1p49tlnmTx5MsFgkD179jB16lT+93//l8LCQkpLS9m+fTtjx47l9ttvJycnp35oyM4K6R2/MaYcSG62rADbyqd7aOBXqscaPXo0JSUlnHjiiaQ5T+zf+c53uOiii8jJySE7O7vNO98bb7yR6667jszMTLKzs+u7TM7KymLcuHGMHj2aoUOHMnHixPptbrjhBqZPn05aWhrLli2rX360bpdbS+sczdNPP82PfvQjysvLGTp0KE899RSBQICrr76aoqIijDH87Gc/IzExkbvuuotly5bh9XoZNWoU06dP7/DxGuvd3TIDbNkCI0fC88+D86iolGqbdsvcs3SkW+be32WDDsailFJN9P7Ar6kepZRqovcHfr8fIiO1OadSndATUsGq4/9OvT/wi2hHbUp1gt/vp6CgQIP/cc4YQ0FBQYde6urdI3DV0Y7alOqwgQMHkpubyzF1maK6hd/vZ+DAge1eXwO/UqpFERERDBkyJNzFUCHQ+1M9YFM9muNXSinALYFf7/iVUqqeBn6llHIZ9wR+TfUopRTglsCfkADl5VBdHe6SKKVU2Lkj8Guf/EopVU8Dv1JKuYw7Ar921KaUUvXcEfi1ozallKqngV8ppVzGHYG/LtWjOX6llHJJ4Nc7fqWUqhfqwdYTReQlEdkiIptF5Osi0ldE3hORbc48KZRlACA2FjweDfxKKUXo7/gfAt42xowAsoDNwBxgiTEmA1jifA8tj0c7alNKKUfIAr+IxAOTgD8DGGOqjTGFwAzgaWe1p4GZoSpDEzoYi1JKAaG94x8K5ANPicgnIvKEiMQA/Y0x+wCceWpLG4vIDSKyWkRWd8lAENpRm1JKAaEN/D5gPPCYMWYcUEYH0jrGmAXGmBxjTE5KSsqxl0Y7alNKKSC0gT8XyDXGrHK+v4S9EOSJSBqAMz8QwjI00FSPUkoBIQz8xpj9wB4RGe4smgZ8BrwOzHaWzQZeC1UZmtBUj1JKAaEfc/cnwHMiEgnsAK7DXmwWisj3gd3AFSEug6WBXymlgBAHfmPMOiCnhZ+mhfK4LUpIgJISCAZt806llHIp90TAxEQwBoqLw10SpZQKK3cFftB0j1LK9dwX+LVJp1LK5dwT+HUwFqWUAtwU+DXVo5RSgBsDv6Z6lFIu557Ar6kepZQCNPArpZTruCfw+3x2QBYN/Eopl3NP4AcdjEUppXBb4Nf+epRSSgO/Ukq5jfsCv6Z6lFIu567Ar4OxKKWUywK/pnqUUsqlgd+YcJdEKaXCxl2BPyEBAgEoLw93SZRSKmzcFfi1ozallNLAr5RSbhPSMXdFZCdQAgSAWmNMjoj0BV4E0oGdwJXGmMOhLEe9uv56tEmnUsrFuuOOf6oxJtsYUzfo+hxgiTEmA1jifO8eesevlFJhSfXMAJ52Pj8NzOy2I2vgV0qpkAd+A7wrImtE5AZnWX9jzD4AZ57a0oYicoOIrBaR1fn5+V1TGh2MRSmlQpvjByYaY/aKSCrwnohsae+GxpgFwAKAnJycrml4r33yK6VUaO/4jTF7nfkBYBFwOpAnImkAzvxAKMvQhN8PUVEa+JVSrhaywC8iMSISV/cZOBfYCLwOzHZWmw28FqoytEi7bVBKuVwoUz39gUUiUnecvxlj3haRj4GFIvJ9YDdwRQjLcCQdjEUp5XIhC/zGmB1AVgvLC4BpoTpum/SOXynlcu56cxc08CulXM99gV9TPUopl3Nf4Nc7fqWUy2ngV0opl3Fn4K+shKqqcJdEKaXCwn2BX3voVEq5nPsCv3bUppRyOQ38SinlMu4L/JrqUUq5nPsCv97xK6VcTgO/Ukq5jPsCv6Z6lFIu16sD/66CMlZ83mz0rthY8Hj0jl8p5Vq9OvD/6f0d3Py3tQSDjQbwEtG3d5VSrtauwC8it4hIvFh/FpG1InJuqAt3rMYNSqS4spadBWVNf0hM1FSPUsq12nvH/z1jTDF2FK0U4DpgXshK1UWyBiUCsG5PYdMfEhL0jl8p5VrtDfzizM8HnjLGrG+07Lh1Smos0ZFe1jcP/JrqUUq5WHsD/xoReRcb+N9xxtINhq5YXcPrEcaemMC63GZpHQ38SikXa2/g/z4wBzjNGFMORGDTPce97EGJbN5bTFVtoGGhDsailHKx9gb+rwNbjTGFInI18CugXZFTRLwi8omIvOF87ysi74nINmee1Lmit0/WoESqA0G27CtpWKh3/EopF2tv4H8MKBeRLOCXwC7gmXZuewuwudH3OcASY0wGsMT5HjJ1FbzrcwsbFiYmQkkJBAItbaKUUr1aewN/rTHGADOAh4wxDwFxbW0kIgOBC4AnGi2eATztfH4amNnu0nbCgAQ/KXFRrNtd2LCw7u3d4uJQHloppY5L7Q38JSJyB/Bd4E0R8WLz/G15EPuE0LgiuL8xZh+AM09taUMRuUFEVovI6vz8/JZWaRcRIWtgIusa3/EnJ9v5V191er9KKdVTtTfwXwVUYdvz7wdOBH7b2gYiciFwwBizpjMFM8YsMMbkGGNyUlJSOrOLetmDEtiRX0ZRRY1dcOaZdr548THtVymleqJ2BX4n2D8HJDgBvdIY01aOfyJwsYjsBF4AzhKRvwJ5IpIG4MwPdLbw7VWX5/+0rlnnkCEwfDj84x+hPrRSSh132ttlw5XAR8AVwJXAKhG5vLVtjDF3GGMGGmPSgVnAUmPM1cDrwGxntdnAa50se7tlnpgINKvgnT4d3n8fystDfXillDqutDfV85/YNvyzjTHXAKcDd3XymPOAc0RkG3AO3dD1Q0J0BEP7xTTtumH6dKiqguXLQ314pZQ6rrQ38HuMMY1TMgUd2BZjzHJjzIXO5wJjzDRjTIYzP9SB8nZa9qBE1u0pxDZOAiZNguhoTfcopVynvcH7bRF5R0SuFZFrgTeBt0JXrK6XNSiR/JIq9hVV2gV+P0ydqoFfKeU67a3c/QWwAMgEsoAFxpjbQ1mwrlb/IlfzdM/27bBtW1jKpJRS4eBr74rGmJeBl0NYlpAamRZHhFdYl1vI9LFpduH06Xb+j39ARkb4CqeUUt2o1Tt+ESkRkeIWphIR6VGvvUb5vIxKi296xz90KAwbpukepZSrtBr4jTFxxpj4FqY4Y0x8dxWyq2QNSuTT3CICjYdinD7dtuypqAhbuZRSqjv16jF3m8samEhZdYAvDpQ2LJw+HSortVmnUso1XBX4swcnAs0qeCdPhj59NN2jlHINVwX+IckxxPl9TTts8/thyhQN/Eop13BV4Pd4bE+dR4zBO306fPGFnZRSqpdzVeAHyBqUwJb9JVTWNBqEpa5Z59tvh6dQSinVjdwX+AcmEggaNu1tNHLkKafYSdM9SikXcF3gz3be4P2k8YhcYO/6ly2zLXyUUqoXc13gT433k5bgZ31us7Hip0+3bfnffz88BVNKqW7iusAP9q7/iAreKVNsCx9N9yilejlXBv6sQYnsPlTOgZJGaZ0+fbRZp1LKFVwZ+KcOt+O7v75ub9Mfpk+Hzz+HHTvCUCqllOoergz8w0+II2tQIgtX72kYmAXgggvs/M9/Dk/BlFKqG7gy8ANclTOIz/NKmw7HePLJcNVV8NBDcCDkY8ArpVRYhCzwi4hfRD4SkfUisklE7nWW9xWR90RkmzNPClUZWnNRVhp9IrwsXL2n6Q/33GNb98wL+VDASikVFqG8468CzjLGZAHZwHkiMgGYAywxxmQAS5zv3S7OH8EFmWm8vm4vZVW1DT+MGAHXXAOPPgpffRWOoimlVEiFLPAbq67/4whnMsAM4Gln+dPAzFCVoS1XnTaIsuoAb366r+kPc+dCMAj33x+egimlVAiFNMcvIl4RWQccAN4zxqwC+htj9gE489RQlqE1OSclMTQlhoUfN0v3pKfD9dfD44/Dl1+GpWxKKRUqIQ38xpiAMSYbGAicLiJj2rutiNwgIqtFZHV+fn5IyiciXJkziNW7DjcdnAXgV78Cnw/uuy8kx1ZKqXDpllY9xphCYDlwHpAnImkAzrzF5jPGmAXGmBxjTE5KSkrIynbp+BPxeoS/N6/kHTAAbroJnnkGtmwJ2fGVUqq7hbJVT4qIJDqf+wBnA1uA14HZzmqzgddCVYb2SI3zc9aIVF5em0tNINj0xzlz7Bu999wTlrIppVQohPKOPw1YJiIbgI+xOf43gHnAOSKyDTjH+R5Ws04bxMHSapZuafbwkZICt94KL74I69eHpWxKKdXVpMmbq8epnJwcs3r16pDtvzYQ5Ix5Sxl7YgJ/vva0pj8WFsKQITBpErwW1ocTpZTqEBFZY4zJab7ctW/uNubzerj81IEs23qAvOJm/fEnJsJtt8Hrr8OqVWEpn1JKdSUN/I4rcwYRNPDSmtwjf7zlFkhNhZtvhtraI39XSqkeRAO/I71fDF8b0peFq/cQDDZLf8XGwh//CKtXw/z54SmgUkp1EQ38jVx12iB2FZTz/rYW3hu44gq47DL7Vu9nn3V/4ZRSqoto4G/k/LFpDOkXw68WbaSksubIFR55BOLi4Hvfg0Cg+wuolFJdQAN/I/4IL/OvyGJfUQX/9cbmI1fo3x/+8Adbyfv733d/AZVSqgto4G/m1JOS+OHkk3lx9R6Wbsk7coVZs2DmTNulw9at3V4+pZQ6Vhr4W3Dr2RmMOCGO21/+lMNl1U1/FIHHHoPoaE35KKV6JA38LYjyeXngymwKy6v51Wsbj1zhhBPg4Yfhww/tXCmlehAN/EcxakA8t549jDc37OP19XuPXOE734GLLoI774Rt27q/gEop1Uka+Fvxw0lDGTc4kbte3XjkG70i8Kc/gd9vLwLl5eEppFJKdZAG/lb4vB5+d0UWVbUB5ry8gSP6NRowAP7yF/ti16xZ+lavUqpH0MDfhqEpscw5bwTLtuYfOTA7wIwZtonn//0f/PSn0AM6vVNKuZsG/na45uvpTBjal/vf3MyBksojV/jxj+H2221rn3lh72VaKaVapYG/HTwe4f5LxlJZE+TXLb3YBfDf/21z/XfeCc8+270FVEqpDtDA304np8Ty46mn8H/r97J8awujRXo88OSTcNZZtn3/4sXdX0illGoHDfwd8KMpQzk5JYZfvbqR8uoWKnIjI+GVV2DkSLj0Uh21Syl1XNLA3wFRPi//c2kmuYcreGjxUdruJyTAW2/Z+TnnwMsvd28hlVKqDRr4O+j0IX2ZddognvjgSzbtLWp5pYED4b337Pzyy+20f3/3FlQppY4iZIFfRAaJyDIR2Swim0TkFmd5XxF5T0S2OfOkUJUhVOZMH0FSdAR3vvIpgeaDttQZMcL24jlvHrzxhk3//OUv2txTKRV2obzjrwX+wxgzEpgA/FhERgFzgCXGmAxgifO9R0mMjuSuC0exPreIv/5719FXjIiwzTzXr4cxY+C66+Cb34SdO7utrEop1VzIAr8xZp8xZq3zuQTYDJwIzACedlZ7GpgZqjKE0sVZA/hGRj9++85W9he10La/seHD4f337UAuK1fai8DKld1TUKWUaqZbcvwikg6MA1YB/Y0x+8BeHIDUo2xzg4isFpHV+fktDIUYZiLC/TPHUhsM8h9/X0dFdRvdM3s8cNNNsGmTHdBl5kzY1crTglJKhUjIA7+IxAIvA7caY4rbu50xZoExJscYk5OSkhK6Ah6DwcnR/HrGGD7cXsDspz5qebjGIzYabHP+VVVw4YVQUhL6giqlVCMhDfwiEoEN+s8ZY15xFueJSJrzexrQwttQPccVOYN4aNY41u46zLce/zcFpVVtbzRyJCxcCJs3w7e+pYO5KKW6VShb9QjwZ2CzMeaBRj+9Dsx2Ps8GXgtVGbrLxVkDePyaHLbllXLl/1vJvqKKtjc691w7iMubb8Ivfxn6QiqllCOUd/wTge8CZ4nIOmc6H5gHnCMi24BznO893tQRqTzzvdPJK67i8sdW8uXBsrY3uukmuPlmeOABeOKJ0BdSKaUAOaKP+eNQTk6OWb16dbiL0S6f5hYx+6mP8Ijw7PdPZ2RafOsb1NbaXP+SJfDuuzB1avcUVCnV64nIGmNMTvPl+uZuFxs7MIGFP/w6EV5h5iP/Ys7LG/g8r5UKXJ8PXnwRhg2Dyy7TYRyVUiGngT8ETkmN5ZWbzuCyUwfy6rqvOPf3K/jun1exbOsBgi296ZuQYAdy8XhsM09t6aOUCiFN9YTY4bJq/vbRbp5ZuZO84ipOTonhB98YylWnDcLWfzeyZImt9J0xA156yV4IlFKqkzTVEyZJMZH8eOop/POXZ/HQrGxionzMeeVTXl771ZErT5sGv/0tLFpkB3ZRSqkQ0MDfTSJ9HmZkn8irN00ke1Aiv3l7C6VVLfTp/7Of2ZG87r7bNvVUSqkupoG/m3k8wtyLRpFfUsUflrZQkSsCCxZAVpa9AGhlr1Kqi2ngD4Nxg5O4bPxAnvzgy5bb+0dH23SPz6eVvUqpLqeBP0xuP284kV4P//XGZy2vkJ5uu3XYuhVmz4ZgsFvLp5TqvTTwh0lqvJ+fTMtgyZYDLQ/eDnbg9rrK3uuu01G8lFJdQgN/GF03MZ305Gjue+MzqmuPckd/660wZw787W9wyikwd66mfpRSx0QDfxhF+bzcdeEoduSX8czKnS2vJAL/8z/w2Wdw/vlw3332AvDII1DTjm6glVKqGQ38YXbWiFQmD0vhocXbONhal84ZGTbnv2qV7db55pth1Ch4/nnb349SSrWTBv4wExHuunAUFTUB5r+zte0NTj8dli2zg7n4/fDtb9t+fh55BMrLQ19gpVSPp4H/OHBKaizXnpHOi6v38N5neW1vIAIXXGAHcV+0yA7lePPNcNJJNhVUUBD6QiuleiwN/MeJn56dwbDUOH7wzGp+9uI6DpVVt71RXaduH34IK1bAhAm28nfwYPjhD22vn3v2hLzsSqmeRTtpO45U1QZ4ZNl2Hl32BQl9Irj7olFcnDXgyM7cWrNpk20CunAhVDgjgZ14Ipxxhp0mToScHPvUoJTq1Y7WSZsG/uPQlv3F3P7yp6zfU8i0Ean81yVjSEvo07Gd1NTAhg32aeDDD2HlSti1y/42YgTceCNccw0kJnZ5+ZVSxwcN/D1MIGh46l9f8rt3P8frEf7zgpHMaqkr547Yu9eO8vWnP9nWQdHRtnL4xhth/PiuK7xS6riggb+H2l1QzpxXNvDh9gKmjUhl3mWZpMRFHfuO166Fxx6D556zKaGvfQ2+/324/HJISjr2/Sulwq7bA7+IPAlcCBwwxoxxlvUFXgTSgZ3AlcaYw23ty82BHyAYNPzlw53Me3sLsVE+5l06lnNHn9A1Oy8shGeesU8BmzdDZCRcdBF897swfbr93nKh7BPEF1/YHkS3bWv4XFEB119vnyQSErqmnEqpDgtH4J8ElALPNAr8/wscMsbME5E5QJIx5va29uX2wF9nW14Jt764jk17i7kqZxB3XTSK2Chf1+zcGFizBp591r4Ulp8Pyclw1VUwdCjk5sJXX9kpNxf27Wv65nBkpF0vIwPKymDpUoiPt8H/llsgLa3l41ZUwMaNEAhAXFzTyddF56aUS4Ul1SMi6cAbjQL/VmCKMWafiKQBy40xw9vajwb+BtW1QR5a8jmPLd/OiUl9+M1lmZxxcr+uPUhNja0LePZZeO01qKy09QEDB9oWQnXzwYNtoD/lFBg0CLzehn188gn85jfw97/bAH7ttfCTn0BRkb3ArF1r55s326Dfkqgoe6yxY+00ZoydZ2ToRUGpdjheAn+hMSax0e+HjTEtJpRF5AbgBoDBgwefuquuRYoCYPXOQ/x84Xp2Hyrn9CF9+fHUU5iU0e/YKn9bUlZmLwQJCZ1rArp9O8yfD089BVWNuqRITYVTT7XTuHH2LeSSEigttfO6aedO+PRT+Pzzhq6po6Ls28qDBx85paTA4cNw4EDT6fBh25rpjDPgtNPshUypXq7HBf7G9I6/ZRXVAV74eDcLVuxgX1ElY06M58dTTuGbo0/A4znO2unv3w+vvGKfDMaPhwEDOnYhqay0TweffmqnrVvty2m7d8OhQ61vGx9vp9xc+93ng+xsexH4+tfh5JNts9a6KSKic+eo1HHmeAn8muoJgeraIK9+8hWPvb+dLw+WcXJKDD/4xlC+OfoEkmKOUjnbm5SWNlwE6uomUlPtlJJinybAXiD+/e+GdxtWrWq5f6PoaHsB6NPo3YnG/594PPa3uik62s5jYqBfv4ZjNy6Dx2OfnGpr7VT3uV8/+6TSOE3WEmPshevwYds5n6a6VDscL4H/t0BBo8rdvsaYX7a1Hw387RMIGv6xcR+PLNvO5n3FeATGD05i2sj+TBuZSkZqbNengnqy2lr79LB3rw2ohYVNp4qKpk8ldZ8DAftb3VRebuelpXDwoE2PdYTfb+sthg+36ajhw21l+datsGWLnbZubdhvTIztnuPMM+2b2BMm2MpwpZoJR6ue54EpQD8gD5gLvAosBAYDu4ErjDFtPKdr4O8oYwwbcotYsuUASzbnsWlvMQCD+vZhyrBUhp0QR3pyNCf1jWFAoh+fV7ts6lJlZfbJo65+4eBBe8fu89k0ks/XMO3f3xDYt26FHTuaVnafdJK9GNRNcXH2qeWDD+yb2cGgfZrIzLQpq0GDGqaBA+08KsoePxhsOvf57EXH77frHOtNQU1Nw3nn59vzPuEEyMqCvn2Pbd+qU/QFLhfbV1TB0i0HWLr5AB9uL6CipiGw+DzCwKQ+DE6OIS7Kh9cj+LyCzyP4vB58HqEmYCivrqWsKmDn1QHKq2qJ8/uYPCyVaSNTGT0gvtNPE7WBIF6P6NMIQHW1rRCvqrIV2K1VQhcX24vAv/5l01a7dtmUV0efOOpERdmLQGKiHfO5+ZScbJvx7t5tj1OXXsvNbahAP5rBg229St2Unt606W6fPvbCYwzk5dl3QhpPeXn2qaiuZdeYMTaF1pwx9unr8GGbRos6hpcdS0rs3zQvz7ZiGzLk2PYXBhr4FWBfBssrqWTnwXJ2HypjV0E5uwrK2XO4nPLqAIGgoSYQpDZgqA0aaoNBfB4PMVFeYiJ9xER5iXbmewsrWZ9biDGQGhfF1OGpTB2RypkZ/dp8v2DnwTKWbT3A0i0HWLXjEP1iI5k0LIXJw1I445R+JPTRCtZOMcamqeoCc26uvRP3eGxgrZuL2CeLyko7VVQ0fC4osAFv50773kZLMULEvptR93Rxwgk2EDeu10hOtsdft65h2rq1oXVWYx6PvQDU1ja9cHm9NuCmpNiWXY27HE9NtYMSBQK2/ubQIRvw61qP+f02DTZpkp0mTLBpsjqBgL1w1b18uH27Pee6qXmjARF7rqecYp+uTj7ZdomelGSnxEQ779vXXrCP5UYmGLT/FuXl9u/SyQuOBn4VEgdLq3h/az5Ltxxgxef5lFTZ0cD6x0cxMCmaQUl97LxvHxKjI/noy0Ms23KAHQft/9xDU2KYlJHC/qJK/vXFQUqqavF6hOxBiUwelkJ6vxgqawJU1QapajSP9HnI6B/H8P5xDO4bffy1YuotqqvtBWTnTpu6SUuzd+8DBhz9re7WlJfbF/a++urIprulpTZYnnxyw/shgwc3tLKqexqoa9m1caNNk/n9DQG3bp6QYAP6ihX2nZJg0Ka2cnLsRWTbNptWq27U/XmfPvYic9JJTZ90UlJseesuDnXz/Pyjn2dyMowefeQUG9uwj8Zvu+fm2r9NXX1RZWXDvt55B849t+N/azTwq25QEwjy8c5DfPzlYfYcLif3cDl7DlWwr6iCoPOfWaTPw4ShyZw1PIWpI1I5KTmmyfbr9hTy/tZ8VmzL59Ovilq82WyuT4SXjP6xDO8fx8mpscRG+egT4aVPpDNFePFHePEe5Q7M6xEifUKk10ukz0Okz0OEV4iOtKkv1cMVFzeMWbFihf2ekdFwcan7nJbWsbv0khJ7MTx8uGGqe/LYscN2kb5pk31p8Wj69bNlOOkke1Fo3lIsOhouvtj+3gka+FXY1ASC7C+q5EBJFSPT4oiObF9TxENl1RwqqyLK5yUqwkOUz4s/wkOk10N5dYBtB0rZur+YrftL+TyvhC37S1oft7gT4qJ8xPeJIKFPBInRdh4T5UNwMiZIfebEI0J0pE2FxUb5iK5Pj/nqt0/sE0FCdARRvjaab6rewRjbaqzuIlBWZgN93RTibtE18CtXKK2qpby6lorqABU1gfp5ZU2gxdSyAQLBINUBQ3Vt0JkCVAeClFUFKKqoobiihiJnKqyoobyqFoP9f9pgnLmtPyl3jteWPhFeEqMjiPB6CBpDMGgIGuxnZx4I2uWBus/GHsvrsZXvXqcC3usRIr0eBvXtw5B+sQzpF+3MYxjcN5pIn4dg0FATtHU3NYEgNQFDVW1d6ixIZW2AqpogVbUBRITkmEhS4qLoGxNJhLb66rGOFvj1LRDVq8RG+bqu47pOCgQNFTUByqpqnSlAcWUNh8urKSx3LiDl1RwuryEQNPVPC14Rp+5V8AjOd7vc67GfBeyFoFHleyBoqKgOsOdwBe9s2t9k2M66fQeCnb/BS4yOoF9sFKlxUWSkxjLsBFu3ktE/rl2V8MbYC6I9b3v+1YFg/XnZCbweD30ivJwQ7ye+j69drbwqawJEej1ax9NBGviV6mJej4T1AlRYXs2XB8vYWVDGlwfLCQSDRHg9ziT4PHbeOIUWFeHB78wDQUNBaRUHS6s5WFpFgTPfW1TJS2tyKatueKI5Id7PyakxeESoCThPTHXz2iClVbUUVdRQE+jYhadPhJe0BD8nOFNSdCRFFTUcKqumoLSKgrJqCkqr65+u6v7ecX4fsX4fcf4IIr0evB7weTzOBRQ8HsEjUl93ZHAe17D/bn1jI0mJjSI5NpLkGDuP90dQWF5Dfmkl+SX275JfYssQ5/eRGhdF/3g//eOjSI3z0z/eT2yUDxG7T49zIRcRqmuDHC6vdtKY1RSUVXOotIrK2iApsVGckGD30z/eT5w/dC3bNPAr1cskRkcybnAk4wZ3/YA6xhi+Kqzg87wSPs8r5fP9JWx3WmhFeT1ER/pIdCrHI31eYqN89XUjiU49R3yfCKJ8HgJB+3QUqE9n2fRaXnEl+4oq2V9Uyf7iSlbtOMShsmoSoyPqA/LJKbEkx0aSGB1JdW2QkspaSiprKK2qpaSylqLyaqoDNlVWGwwSNA3HMsY0eZqoq6Oprg1yqKy6XRepOL+P5JhISqtqOVha3eb6AB6Bjjx4xUR66Z/g578vGcuEocnt37AdNPArpdpNRBiYFM3ApGjOGtE/3MXpcsYYSqpqKSitrn/qKa6oITE6gpS4KFLiougXG4U/oqFyvro2yMHSKvKKK8krtvOKmkB9HU3Q2PScMYYIr4e+MZEkx0SS5Mz7xkTij/CSX1LF/uJK8oobLnp5xZUkRnf9nb8GfqWUcogI8f4I4v0RDOkX0/YG2CbKAxL7MCCxT9srtyImykd6O495rLS6XimlXEYDv1JKuYwGfqWUchkN/Eop5TIa+JVSymU08CullMto4FdKKZfRwK+UUi7TI3rnFJF8YFcnN+8HHOzC4vQUet7u49Zz1/M+upOMMUeMUdkjAv+xEJHVLXVL2tvpebuPW89dz7vjNNWjlFIuo4FfKaVcxg2Bf0G4CxAmet7u49Zz1/PuoF6f41dKKdWUG+74lVJKNaKBXymlXKZXB34ROU9EtorIFyIyJ9zlCRUReVJEDojIxkbL+orIeyKyzZl3/Th8YSYig0RkmYhsFpFNInKLs7xXn7uI+EXkIxFZ75z3vc7yXn3edUTEKyKfiMgbzvdef94islNEPhWRdSKy2lnW6fPutYFfRLzAI8B0YBTwLREZFd5ShcxfgPOaLZsDLDHGZABLnO+9TS3wH8aYkcAE4MfOv3FvP/cq4CxjTBaQDZwnIhPo/edd5xZgc6PvbjnvqcaY7EZt9zt93r028AOnA18YY3YYY6qBF4AZYS5TSBhjVgCHmi2eATztfH4amNmdZeoOxph9xpi1zucSbDA4kV5+7sYqdb5GOJOhl583gIgMBC4Anmi0uNef91F0+rx7c+A/EdjT6Huus8wt+htj9oENkEBqmMsTUiKSDowDVuGCc3fSHeuAA8B7xhhXnDfwIPBLINhomRvO2wDvisgaEbnBWdbp8+7Ng61LC8u07WovJCKxwMvArcaYYpGW/ul7F2NMAMgWkURgkYiMCXORQk5ELgQOGGPWiMiUMBenu000xuwVkVTgPRHZciw76813/LnAoEbfBwJ7w1SWcMgTkTQAZ34gzOUJCRGJwAb954wxrziLXXHuAMaYQmA5to6nt5/3ROBiEdmJTd2eJSJ/pfefN8aYvc78ALAIm8ru9Hn35sD/MZAhIkNEJBKYBbwe5jJ1p9eB2c7n2cBrYSxLSIi9tf8zsNkY80Cjn3r1uYtIinOnj4j0Ac4GttDLz9sYc4cxZqAxJh37//NSY8zV9PLzFpEYEYmr+wycC2zkGM67V7+5KyLnY3OCXuBJY8z94S1RaIjI88AUbDetecBc4FVgITAY2A1cYYxpXgHco4nImcA/gU9pyPneic3z99pzF5FMbGWeF3vzttAYc5+IJNOLz7sxJ9VzmzHmwt5+3iIyFHuXDzY9/zdjzP3Hct69OvArpZQ6Um9O9SillGqBBn6llHIZDfxKKeUyGviVUsplNPArpZTLaOBXriIi/yMiU0RkZrh6bBWR5SLiusHB1fFDA79ym69h2/lPxr4DoJTraOBXriAivxWRDcBpwErgeuAxEbm7hXVTRORlEfnYmSY6y+8RkWdFZKnTB/oPnOXi7H+j02f6VY329Utn2XoRmdfoMFc4fep/LiLfcNYd7SxbJyIbRCQjhH8S5WK9uZM2peoZY34hIn8Hvgv8HFhujJl4lNUfAn5vjPlARAYD7wAjnd8ysX3/xwCfiMibwNex/eJnYd+e/lhEVjjLZgJfM8aUi0jfRsfwGWNOd94un4vtduFHwEPGmOecbka8XXP2SjWlgV+5yThgHTAC+KyV9c4GRjXq5TO+rq8U4DVjTAVQISLLsJ1lnQk87/SYmSci72OfLCYDTxljygGavU5f16HcGiDd+bwS+E+nz/lXjDHbOnuiSrVGA7/q9UQkGztK2UDgIBBtF8s64OtOIG/M09Jy50LQvI8TQ8tdgOMsP1qfKFXOPIDz/6Ex5m8isgo70Mg7InK9MWZpa+emVGdojl/1esaYdcaYbOBz7DCcS4FvOsPYNQ/6AO8CN9d9cS4cdWaIHfM2Gdsx3sfACuAqZ3CUFGAS8JGzn++JSLSzn8apniM4nXHtMMY8jO15MbMTp6tUmzTwK1dwAvJhY0wQGGGMaS3V81Mgx6lg/Qybe6/zEfAm8G/g104/6YuADcB67EXll8aY/caYt7EBfLXzdHFbG8W8CtjorDsCeKaDp6lUu2jvnEq1k4jcA5QaY+aHuyxKHQu941dKKZfRO36llHIZveNXSimX0cCvlFIuo4FfKaVcRgO/Ukq5jAZ+pZRymf8Pwv8gmo815YQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trainDataVecs[:,:,0],trainDataVecs[:,:,3], c='grey', s=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn=Xn['essay']\n",
    "sent=[]\n",
    "for essay in Xn:    \n",
    "    sent +=Make_sentences(essay, remove_stopwords = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-bfbdf349e314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sent' is not defined"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sent,vector_size=300, workers=num_workers, min_count = min_word_count, window = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('word2vecmodel2.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"Dearlike talking and becoming friends will others through websites like facebook and mysace. Using computers can help us find coordibates, locations, and able ourselfs to millions of information. Also computers will benefit us by helping with jobs as in planning a house plan and typing a @NUM1 page report for one of our jobs in less than writing it. Now lets go into the wonder world of technology. Using a computer will help us in life by talking or making friends on line. Many people have myspace, facebooks, aim, these all benefit us by having conversations with one another. Many people believe computers are bad but how can you make friends if you can never talk to them? I am very fortunate for having a computer that can help with not only school work but my social life and how I make friends. Computers help us with finding our locations, coordibates and millions of information online. If we didn't go on the internet a lot we wouldn't know how to go onto websites that @MONTH1 help us with locations and coordinates like @LOCATION1. Would you rather use a computer or be in @LOCATION3. When your supposed to be vacationing in @LOCATION2. Million of information is found on the internet. You can as almost every question and a computer will have it. Would you rather easily draw up a house plan on the computers or take @NUM1 hours doing one by hand with ugly erazer marks all over it, you are garrenteed that to find a job with a drawing like that. Also when appling for a job many workers must write very long papers like a @NUM3 word essay on why this job fits you the most, and many people I know don't like writing @NUM3 words non-stopp for hours when it could take them I hav an a computer. That is why computers we needed a lot now adays. I hope this essay has impacted your descion on computers because they are great machines to work with. The other day I showed my mom how to use a computer and she said it was the greatest invention sense sliced bread! Now go out and buy a computer to help you chat online with friends, find locations and millions of information on one click of t your self with getting a job with neat, prepared, printed work that your boss will love.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = './finalnew_lstm.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ca6432bbbf82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./finalnew_lstm.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclean_test_essays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclean_test_essays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtestDataVecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mclean_test_essays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtestDataVecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDataVecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2228\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './finalnew_lstm.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "lstm_model.load_weights(\"./finalnew_lstm.h5\")\n",
    "clean_test_essays = []\n",
    "clean_test_essays.append(wordlist( a, remove_stopwords=True ))\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "testDataVecs = np.array(testDataVecs)\n",
    "testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "preds = lstm_model.predict(testDataVecs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-89521834071b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkmeans_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"k-means++\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \"\"\"\n\u001b[1;32m-> 1030\u001b[1;33m         X = self._validate_data(X, accept_sparse='csr',\n\u001b[0m\u001b[0;32m   1031\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                                 \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\""
     ]
    }
   ],
   "source": [
    "kmeans_test = KMeans(n_clusters= 3, init=\"k-means++\", max_iter=500, algorithm = 'auto')\n",
    "fitted = kmeans_test.fit(X)\n",
    "prediction = kmeans_test.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=prediction, s=30)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "kmeans_test.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
