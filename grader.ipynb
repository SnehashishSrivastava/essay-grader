{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run these after removing hastag if any on of the given module is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hastag if having problem with gensim\n",
    "import sys\n",
    "\n",
    "#!$sys.executable -m pip install keras\n",
    "#!$sys.executable -m pip install nltk\n",
    "import nltk\n",
    "\n",
    "#!$sys.executable -m pip install gensim\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#!$sys.executable -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR=\"Dataset and discription/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(columns=['rater1_domain1','rater2_domain1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  \n",
       "0                  8  \n",
       "1                  9  \n",
       "2                  7  \n",
       "3                 10  \n",
       "4                  8  \n",
       "...              ...  \n",
       "12971             35  \n",
       "12972             32  \n",
       "12973             40  \n",
       "12974             40  \n",
       "12975             40  \n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=X['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
    "maximum_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  score  \n",
       "0                  8    6.0  \n",
       "1                  9    7.0  \n",
       "2                  7    5.0  \n",
       "3                 10    8.0  \n",
       "4                  8    6.0  \n",
       "...              ...    ...  \n",
       "12971             35    6.0  \n",
       "12972             32    5.0  \n",
       "12973             40    7.0  \n",
       "12974             40    7.0  \n",
       "12975             40    7.0  \n",
       "\n",
       "[12976 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_min = minimum_scores[X['essay_set']]\n",
    "old_max = maximum_scores[X['essay_set']]\n",
    "old_range = old_max - old_min \n",
    "new_range = (10 - 0)  \n",
    "X['score'] = np.around((((X['domain1_score'] - old_min) * new_range) / old_range) )\n",
    "\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokanization and vectorization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "def wordlist(essay, remove_stopwords):\n",
    "    \n",
    "    essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
    "    words = essay.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_sentences(essay, remove_stopwords):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    \n",
    "    featureVec = np.zeros((num_features),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of pre processing , tokanization then vectorivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of tokanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function', 'tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega'], ['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function', 'tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega'], ['hi', 'example', 'sentence', 'explain', 'thw', 'working', 'function', 'tiwari', 'pakhandi', 'hai', 'shayad', 'isecay', 'samajh', 'aa', 'jayega']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "example2='hi I am an example1 sentence here to explain thw working of above function ,Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "example1='hi I am an example22 sentence here to explain thw working of above function ,Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "example3='hi I am an example33 sentence here to explain thw working of above function ,Tiwari pakhandi hai,shayad isecay samajh me aa jayega'\n",
    "s=[]\n",
    "s +=Make_sentences(example1,remove_stopwords=True)\n",
    "s +=Make_sentences(example2,remove_stopwords=True)\n",
    "s +=Make_sentences(example3,remove_stopwords=True)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=15, vector_size=100, alpha=0.025)\n",
      "['jayega', 'aa', 'samajh', 'isecay', 'shayad', 'hai', 'pakhandi', 'tiwari', 'function', 'working', 'thw', 'explain', 'sentence', 'example', 'hi']\n",
      "[ 7.7010952e-03  9.1176201e-03  1.1432337e-03 -8.3244424e-03\n",
      "  8.4187957e-03 -3.7004054e-03  5.7439804e-03  4.3956689e-03\n",
      "  9.6870130e-03 -9.3018962e-03  9.2124315e-03 -9.2854947e-03\n",
      " -6.9060475e-03 -9.1049811e-03 -5.5488548e-03  7.3718932e-03\n",
      "  9.1690263e-03 -3.3273669e-03  3.7213692e-03 -3.6347338e-03\n",
      "  7.8824461e-03  5.8715679e-03  4.1775697e-06 -3.6322384e-03\n",
      " -7.2279074e-03  4.7728908e-03  1.4499833e-03 -2.6092341e-03\n",
      "  7.8357616e-03 -4.0453337e-03 -9.1553936e-03 -2.2538740e-03\n",
      "  1.3046118e-04 -6.6413041e-03 -5.4882122e-03 -8.5001048e-03\n",
      "  9.2311958e-03  7.4223080e-03 -2.9928688e-04  7.3693860e-03\n",
      "  7.9533989e-03 -7.8221509e-04  6.6067595e-03  3.7699135e-03\n",
      "  5.0775735e-03  7.2475909e-03 -4.7450820e-03 -2.1844471e-03\n",
      "  8.7563385e-04  4.2404803e-03  3.2983597e-03  5.0968025e-03\n",
      "  4.5875884e-03 -8.4412089e-03 -3.1823812e-03 -7.2356355e-03\n",
      "  9.6775386e-03  5.0060744e-03  1.7419278e-04  4.1204351e-03\n",
      " -7.6578925e-03 -6.2970850e-03  3.0768123e-03  6.5375874e-03\n",
      "  3.9471774e-03  6.0223322e-03 -1.9929719e-03 -3.3441694e-03\n",
      "  2.0678154e-04 -3.1985217e-03 -5.5122850e-03 -7.7836574e-03\n",
      "  6.5367655e-03 -1.0923872e-03 -1.8913450e-03 -7.8015588e-03\n",
      "  9.3461946e-03  8.6114055e-04  1.7694257e-03  2.4890536e-03\n",
      " -7.3881038e-03  1.6422297e-03  2.9774487e-03 -8.5607423e-03\n",
      "  4.9514221e-03  2.4336968e-03  7.5001298e-03  5.0495388e-03\n",
      " -3.0273288e-03 -7.1607302e-03  7.1002254e-03  1.9018836e-03\n",
      "  5.1981718e-03  6.3860337e-03  1.9135267e-03 -6.1276378e-03\n",
      " -6.0059351e-06  8.2649551e-03 -6.0937381e-03  9.4371568e-03]\n",
      "Word2Vec(vocab=15, vector_size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(s, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.index_to_key )\n",
    "print(words)\n",
    "# access vector for one word\n",
    "print(model.wv['hi'])\n",
    "# save model\n",
    "model.save('model.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onto the real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-22df307bcade>:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 7s 19ms/step - loss: 21.2342 - accuracy: 0.1115 - val_loss: 491.5340 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 5.1590 - accuracy: 0.1484 - val_loss: 406.6343 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 4.1367 - accuracy: 0.1473 - val_loss: 388.0894 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 3.8829 - accuracy: 0.1433 - val_loss: 366.6861 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 3.5771 - accuracy: 0.1457 - val_loss: 369.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 3.0849 - accuracy: 0.1432 - val_loss: 352.4724 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-006.model\\assets\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 3.2449 - accuracy: 0.1474 - val_loss: 337.2237 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 3.1084 - accuracy: 0.1509 - val_loss: 344.5972 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.9191 - accuracy: 0.1518 - val_loss: 327.1505 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.7572 - accuracy: 0.1466 - val_loss: 321.5711 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.7405 - accuracy: 0.1567 - val_loss: 327.3767 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.5049 - accuracy: 0.1506 - val_loss: 312.2003 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-012.model\\assets\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.6552 - accuracy: 0.1437 - val_loss: 291.7403 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-013.model\\assets\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4245 - accuracy: 0.1483 - val_loss: 319.8779 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.4898 - accuracy: 0.1566 - val_loss: 297.4433 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.3027 - accuracy: 0.1508 - val_loss: 292.2453 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4505 - accuracy: 0.1555 - val_loss: 310.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4174 - accuracy: 0.1540 - val_loss: 301.6313 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.1363 - accuracy: 0.14 - 2s 13ms/step - loss: 2.1370 - accuracy: 0.1495 - val_loss: 296.5426 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.2250 - accuracy: 0.1517 - val_loss: 283.8904 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-020.model\\assets\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.2175 - accuracy: 0.1515 - val_loss: 293.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 2.1424 - accuracy: 0.1527 - val_loss: 273.4039 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 2.2503 - accuracy: 0.1505 - val_loss: 286.6031 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.0377 - accuracy: 0.1513 - val_loss: 283.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.0015 - accuracy: 0.1482 - val_loss: 264.7451 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-025.model\\assets\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.2218 - accuracy: 0.1503 - val_loss: 275.8346 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.2329 - accuracy: 0.1505 - val_loss: 271.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.1333 - accuracy: 0.1544 - val_loss: 260.9986 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-028.model\\assets\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.3555 - accuracy: 0.1492 - val_loss: 283.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.9879 - accuracy: 0.1508 - val_loss: 265.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9754 - accuracy: 0.1519 - val_loss: 265.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9704 - accuracy: 0.1505 - val_loss: 262.4769 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.0449 - accuracy: 0.1582 - val_loss: 261.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.1084 - accuracy: 0.1489 - val_loss: 245.0929 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-034.model\\assets\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9244 - accuracy: 0.1540 - val_loss: 274.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9433 - accuracy: 0.1563 - val_loss: 274.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.7425 - accuracy: 0.1536 - val_loss: 258.1729 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9214 - accuracy: 0.1508 - val_loss: 267.0868 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.7222 - accuracy: 0.1513 - val_loss: 255.7406 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 2s 14ms/step - loss: 1.7039 - accuracy: 0.1506 - val_loss: 266.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9256 - accuracy: 0.1559 - val_loss: 259.7664 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8590 - accuracy: 0.1601 - val_loss: 270.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8309 - accuracy: 0.1579 - val_loss: 256.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8139 - accuracy: 0.1583 - val_loss: 263.2798 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7419 - accuracy: 0.1525 - val_loss: 277.7682 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6637 - accuracy: 0.1525 - val_loss: 257.0496 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7564 - accuracy: 0.1484 - val_loss: 267.6151 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.8321 - accuracy: 0.1531 - val_loss: 262.2496 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 2s 10ms/step - loss: 1.6847 - accuracy: 0.1490 - val_loss: 272.0439 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8029 - accuracy: 0.1588 - val_loss: 277.7531 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7305144049241028\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-22df307bcade>:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 6s 13ms/step - loss: 22.5040 - accuracy: 0.1080 - val_loss: 499.3449 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 1s 10ms/step - loss: 5.6120 - accuracy: 0.1480 - val_loss: 431.1127 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 10ms/step - loss: 4.2570 - accuracy: 0.1562 - val_loss: 396.9512 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 3.8472 - accuracy: 0.1466 - val_loss: 378.3102 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 3.5862 - accuracy: 0.1453 - val_loss: 368.6721 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-005.model\\assets\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 3.6080 - accuracy: 0.1415 - val_loss: 356.6446 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-006.model\\assets\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 3.2669 - accuracy: 0.1472 - val_loss: 344.8865 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 3.2282 - accuracy: 0.1404 - val_loss: 360.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 3.1443 - accuracy: 0.1449 - val_loss: 334.3676 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.9594 - accuracy: 0.1441 - val_loss: 321.4269 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.8746 - accuracy: 0.1515 - val_loss: 315.4391 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-011.model\\assets\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.7660 - accuracy: 0.1516 - val_loss: 330.7207 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.5468 - accuracy: 0.1433 - val_loss: 340.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4349 - accuracy: 0.1499 - val_loss: 338.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4301 - accuracy: 0.1525 - val_loss: 324.8785 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.4796 - accuracy: 0.1553 - val_loss: 317.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 2.4952 - accuracy: 0.1407 - val_loss: 315.4048 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-017.model\\assets\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.4855 - accuracy: 0.1473 - val_loss: 324.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.3608 - accuracy: 0.1525 - val_loss: 296.9068 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-019.model\\assets\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0662 - accuracy: 0.1453 - val_loss: 311.5768 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.4003 - accuracy: 0.1481 - val_loss: 314.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.2239 - accuracy: 0.1573 - val_loss: 306.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.3069 - accuracy: 0.1513 - val_loss: 304.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.2013 - accuracy: 0.1505 - val_loss: 307.7212 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.1611 - accuracy: 0.1568 - val_loss: 305.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9947 - accuracy: 0.1526 - val_loss: 308.5214 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.1223 - accuracy: 0.1542 - val_loss: 308.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 2.0122 - accuracy: 0.1575 - val_loss: 310.8362 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.0807 - accuracy: 0.1493 - val_loss: 295.8109 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-029.model\\assets\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.0621 - accuracy: 0.1542 - val_loss: 314.3632 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9765 - accuracy: 0.1553 - val_loss: 288.4201 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-031.model\\assets\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.8928 - accuracy: 0.1524 - val_loss: 301.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.0073 - accuracy: 0.1510 - val_loss: 265.3069 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-033.model\\assets\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.2255 - accuracy: 0.1579 - val_loss: 288.2156 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 5s 32ms/step - loss: 1.8205 - accuracy: 0.1472 - val_loss: 305.3362 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 1.8491 - accuracy: 0.1529 - val_loss: 309.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.8746 - accuracy: 0.1506 - val_loss: 308.7871 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9496 - accuracy: 0.1540 - val_loss: 285.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.8277 - accuracy: 0.1519 - val_loss: 307.3115 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 3s 17ms/step - loss: 1.8103 - accuracy: 0.1496 - val_loss: 295.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.9727 - accuracy: 0.1557 - val_loss: 301.5378 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.8157 - accuracy: 0.1453 - val_loss: 281.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.9279 - accuracy: 0.1530 - val_loss: 289.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.6895 - accuracy: 0.1521 - val_loss: 310.5026 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.8746 - accuracy: 0.1525 - val_loss: 297.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.7369 - accuracy: 0.1543 - val_loss: 282.3552 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.7926 - accuracy: 0.1586 - val_loss: 303.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.7083 - accuracy: 0.1488 - val_loss: 287.1563 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 4s 30ms/step - loss: 1.7545 - accuracy: 0.1533 - val_loss: 296.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.7598 - accuracy: 0.1512 - val_loss: 290.8961 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7293055123801024\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-22df307bcade>:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 6s 15ms/step - loss: 22.8839 - accuracy: 0.1110 - val_loss: 509.1274 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 5.9632 - accuracy: 0.1494 - val_loss: 414.0520 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 4.3445 - accuracy: 0.1477 - val_loss: 389.8460 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 3.5524 - accuracy: 0.1523 - val_loss: 370.8807 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 3.2224 - accuracy: 0.1452 - val_loss: 368.1631 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-005.model\\assets\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 3.3299 - accuracy: 0.1532 - val_loss: 379.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 3.2549 - accuracy: 0.1467 - val_loss: 375.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.8550 - accuracy: 0.1509 - val_loss: 371.6193 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.9767 - accuracy: 0.1467 - val_loss: 338.9441 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.8324 - accuracy: 0.1477 - val_loss: 335.8237 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.4302 - accuracy: 0.1513 - val_loss: 328.5789 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-011.model\\assets\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.6454 - accuracy: 0.1551 - val_loss: 337.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 4s 30ms/step - loss: 2.7758 - accuracy: 0.1516 - val_loss: 336.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.5054 - accuracy: 0.1541 - val_loss: 336.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 5s 35ms/step - loss: 2.4668 - accuracy: 0.1539 - val_loss: 324.9185 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-015.model\\assets\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 3s 23ms/step - loss: 2.4850 - accuracy: 0.1488 - val_loss: 319.6743 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-016.model\\assets\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 5s 32ms/step - loss: 2.5700 - accuracy: 0.1448 - val_loss: 324.3657 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 2.2719 - accuracy: 0.1525 - val_loss: 309.5396 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-018.model\\assets\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.1860 - accuracy: 0.1508 - val_loss: 298.3949 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-019.model\\assets\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.1960 - accuracy: 0.1519 - val_loss: 333.1801 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 7s 46ms/step - loss: 2.3658 - accuracy: 0.1541 - val_loss: 308.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 7s 47ms/step - loss: 2.2032 - accuracy: 0.1561 - val_loss: 288.1279 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.0033 - accuracy: 0.1488 - val_loss: 297.1174 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 2.3456 - accuracy: 0.1514 - val_loss: 294.3933 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 2.1420 - accuracy: 0.1543 - val_loss: 308.5100 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.1143 - accuracy: 0.1489 - val_loss: 315.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 7s 46ms/step - loss: 2.0546 - accuracy: 0.1528 - val_loss: 298.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.9687 - accuracy: 0.1477 - val_loss: 316.6787 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9390 - accuracy: 0.1569 - val_loss: 310.6675 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.9487 - accuracy: 0.1541 - val_loss: 288.8056 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.8986 - accuracy: 0.1509 - val_loss: 326.6049 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.2084 - accuracy: 0.1483 - val_loss: 306.1808 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 7s 46ms/step - loss: 1.9580 - accuracy: 0.1519 - val_loss: 309.1003 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.8397 - accuracy: 0.1533 - val_loss: 312.9789 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9836 - accuracy: 0.1519 - val_loss: 295.6819 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 5s 33ms/step - loss: 1.8787 - accuracy: 0.1535 - val_loss: 294.5334 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.8988 - accuracy: 0.1517 - val_loss: 298.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.7797 - accuracy: 0.1513 - val_loss: 320.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 1.9514 - accuracy: 0.1525 - val_loss: 309.4901 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.8457 - accuracy: 0.1443 - val_loss: 294.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 5s 34ms/step - loss: 1.8530 - accuracy: 0.1536 - val_loss: 297.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 1.8341 - accuracy: 0.1563 - val_loss: 322.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 5s 37ms/step - loss: 1.7850 - accuracy: 0.1534 - val_loss: 277.7665 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-043.model\\assets\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 4s 25ms/step - loss: 1.8705 - accuracy: 0.1502 - val_loss: 287.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 1.7933 - accuracy: 0.1594 - val_loss: 290.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.7007 - accuracy: 0.1563 - val_loss: 296.1932 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 4s 28ms/step - loss: 1.7808 - accuracy: 0.1475 - val_loss: 302.5997 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 1.7935 - accuracy: 0.1536 - val_loss: 305.8547 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.8099 - accuracy: 0.1575 - val_loss: 297.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.8029 - accuracy: 0.1548 - val_loss: 314.5776 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7133894492439586\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-22df307bcade>:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 6s 17ms/step - loss: 23.5130 - accuracy: 0.0958 - val_loss: 502.2188 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 5.6134 - accuracy: 0.1430 - val_loss: 418.3440 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 4.1996 - accuracy: 0.1496 - val_loss: 376.7475 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 3s 23ms/step - loss: 3.7200 - accuracy: 0.1446 - val_loss: 376.1536 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 3.7895 - accuracy: 0.1451 - val_loss: 368.5110 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-005.model\\assets\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 3.4975 - accuracy: 0.1439 - val_loss: 353.1693 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-006.model\\assets\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 3.0960 - accuracy: 0.1496 - val_loss: 352.4760 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 3.2933 - accuracy: 0.1553 - val_loss: 345.9906 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-008.model\\assets\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 2.8887 - accuracy: 0.1464 - val_loss: 321.1723 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-009.model\\assets\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 3.1198 - accuracy: 0.1531 - val_loss: 321.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 5s 33ms/step - loss: 2.7211 - accuracy: 0.1465 - val_loss: 342.0990 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.5388 - accuracy: 0.1470 - val_loss: 314.9977 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-012.model\\assets\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 2.6575 - accuracy: 0.1519 - val_loss: 316.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 8s 52ms/step - loss: 2.5450 - accuracy: 0.1483 - val_loss: 291.1048 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-014.model\\assets\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.4910 - accuracy: 0.1466 - val_loss: 303.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 2.5482 - accuracy: 0.1466 - val_loss: 282.8183 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-016.model\\assets\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 4s 25ms/step - loss: 2.5252 - accuracy: 0.1478 - val_loss: 288.0423 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.2565 - accuracy: 0.1552 - val_loss: 304.3126 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 7s 51ms/step - loss: 2.2818 - accuracy: 0.1424 - val_loss: 295.3852 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 2.2322 - accuracy: 0.1523 - val_loss: 283.3819 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 4s 27ms/step - loss: 2.3074 - accuracy: 0.1471 - val_loss: 287.7391 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 2.2829 - accuracy: 0.1439 - val_loss: 276.9848 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.0983 - accuracy: 0.1503 - val_loss: 291.3966 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.2673 - accuracy: 0.1494 - val_loss: 282.7929 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 7s 49ms/step - loss: 2.1908 - accuracy: 0.1538 - val_loss: 287.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.3916 - accuracy: 0.1458 - val_loss: 276.4956 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-026.model\\assets\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 2.1425 - accuracy: 0.1522 - val_loss: 280.2574 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 7s 50ms/step - loss: 2.3670 - accuracy: 0.1552 - val_loss: 269.7767 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-028.model\\assets\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 2.2469 - accuracy: 0.1548 - val_loss: 278.3241 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 2.0620 - accuracy: 0.1520 - val_loss: 278.6440 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 8s 54ms/step - loss: 1.9348 - accuracy: 0.1519 - val_loss: 279.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.9239 - accuracy: 0.1472 - val_loss: 272.0988 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 8s 53ms/step - loss: 2.0570 - accuracy: 0.1501 - val_loss: 275.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.9976 - accuracy: 0.1541 - val_loss: 265.9664 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-034.model\\assets\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 2.0080 - accuracy: 0.1560 - val_loss: 262.1406 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-035.model\\assets\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 4s 27ms/step - loss: 1.9580 - accuracy: 0.1509 - val_loss: 272.5539 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.8772 - accuracy: 0.1556 - val_loss: 264.7141 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.7365 - accuracy: 0.1565 - val_loss: 280.5273 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 3s 18ms/step - loss: 1.9074 - accuracy: 0.1593 - val_loss: 268.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 4s 28ms/step - loss: 1.9378 - accuracy: 0.1473 - val_loss: 276.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.8527 - accuracy: 0.1591 - val_loss: 263.9925 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.7632 - accuracy: 0.1490 - val_loss: 278.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 8s 54ms/step - loss: 1.7294 - accuracy: 0.1541 - val_loss: 268.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 8s 53ms/step - loss: 1.7993 - accuracy: 0.1585 - val_loss: 271.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.8905 - accuracy: 0.1532 - val_loss: 267.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 8s 55ms/step - loss: 1.8423 - accuracy: 0.1525 - val_loss: 268.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 8s 55ms/step - loss: 1.8646 - accuracy: 0.1567 - val_loss: 265.5093 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 8s 54ms/step - loss: 1.7749 - accuracy: 0.1533 - val_loss: 275.4567 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.7190 - accuracy: 0.1533 - val_loss: 253.7039 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-049.model\\assets\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.7558 - accuracy: 0.1525 - val_loss: 251.1383 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-050.model\\assets\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.760571001696327\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-22df307bcade>:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 7s 21ms/step - loss: 22.1011 - accuracy: 0.1084 - val_loss: 513.4291 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-001.model\\assets\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 5.7067 - accuracy: 0.1537 - val_loss: 410.1570 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-002.model\\assets\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 4.2088 - accuracy: 0.1501 - val_loss: 397.6617 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-003.model\\assets\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 10s 66ms/step - loss: 3.7991 - accuracy: 0.1507 - val_loss: 375.2723 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-004.model\\assets\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 4s 30ms/step - loss: 3.4037 - accuracy: 0.1429 - val_loss: 345.6275 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-005.model\\assets\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 3.3087 - accuracy: 0.1619 - val_loss: 369.0220 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 10s 66ms/step - loss: 3.0983 - accuracy: 0.1543 - val_loss: 334.2173 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-007.model\\assets\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 2.8279 - accuracy: 0.1482 - val_loss: 339.4792 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 10s 67ms/step - loss: 2.8925 - accuracy: 0.1489 - val_loss: 346.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 9s 63ms/step - loss: 2.5410 - accuracy: 0.1460 - val_loss: 323.7159 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-010.model\\assets\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 2.5050 - accuracy: 0.1499 - val_loss: 323.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 10s 66ms/step - loss: 2.5028 - accuracy: 0.1493 - val_loss: 316.0620 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-012.model\\assets\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 3s 22ms/step - loss: 2.4146 - accuracy: 0.1438 - val_loss: 324.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 10s 67ms/step - loss: 2.3928 - accuracy: 0.1483 - val_loss: 302.9955 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-014.model\\assets\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 2.3387 - accuracy: 0.1529 - val_loss: 318.8734 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 5s 33ms/step - loss: 2.3841 - accuracy: 0.1510 - val_loss: 311.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 7s 49ms/step - loss: 2.2707 - accuracy: 0.1504 - val_loss: 310.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 10s 67ms/step - loss: 2.4026 - accuracy: 0.1508 - val_loss: 318.7821 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 8s 55ms/step - loss: 2.3695 - accuracy: 0.1521 - val_loss: 293.3031 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-019.model\\assets\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 2.1188 - accuracy: 0.1507 - val_loss: 299.6479 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 9s 65ms/step - loss: 2.2246 - accuracy: 0.1462 - val_loss: 288.0956 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-021.model\\assets\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 2.1184 - accuracy: 0.1498 - val_loss: 284.8574 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-022.model\\assets\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 2.1636 - accuracy: 0.1624 - val_loss: 303.8079 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 8s 52ms/step - loss: 2.1668 - accuracy: 0.1538 - val_loss: 296.7248 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 5s 32ms/step - loss: 2.0583 - accuracy: 0.1516 - val_loss: 300.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 9s 59ms/step - loss: 1.9738 - accuracy: 0.1490 - val_loss: 302.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 9s 59ms/step - loss: 2.2658 - accuracy: 0.1507 - val_loss: 308.6104 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 8s 57ms/step - loss: 2.0511 - accuracy: 0.1508 - val_loss: 307.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 9s 59ms/step - loss: 2.0148 - accuracy: 0.1528 - val_loss: 284.0222 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-029.model\\assets\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 7s 48ms/step - loss: 1.9853 - accuracy: 0.1489 - val_loss: 306.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 1.9622 - accuracy: 0.1480 - val_loss: 309.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 3s 21ms/step - loss: 2.0286 - accuracy: 0.1509 - val_loss: 290.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 9s 62ms/step - loss: 2.0351 - accuracy: 0.1485 - val_loss: 293.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 1.9425 - accuracy: 0.1507 - val_loss: 279.6629 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-034.model\\assets\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 2.0326 - accuracy: 0.1456 - val_loss: 290.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 9s 63ms/step - loss: 1.8820 - accuracy: 0.1520 - val_loss: 286.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 9s 62ms/step - loss: 1.8422 - accuracy: 0.1610 - val_loss: 285.8748 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 1.8570 - accuracy: 0.1531 - val_loss: 278.2850 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-038.model\\assets\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 9s 62ms/step - loss: 1.8108 - accuracy: 0.1504 - val_loss: 306.7000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 3s 20ms/step - loss: 1.9017 - accuracy: 0.1485 - val_loss: 283.4006 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 1.7943 - accuracy: 0.1502 - val_loss: 283.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 9s 64ms/step - loss: 1.7211 - accuracy: 0.1514 - val_loss: 269.1360 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: model-042.model\\assets\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 1.8300 - accuracy: 0.1524 - val_loss: 296.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - ETA: 0s - loss: 1.7774 - accuracy: 0.1578"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "count=1\n",
    "results=[]\n",
    "for train,test in skf.split(X,Y):\n",
    "        print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "        X_test, X_train, y_test, y_train = X.iloc[test], X.iloc[train], Y.iloc[test], Y.iloc[train]\n",
    "        trainE = X_train['essay']\n",
    "        testE= X_test['essay']\n",
    "        sentences=[]\n",
    "        for essay in trainE:\n",
    "        # Obtaining all sentences from the training essays.\n",
    "        \n",
    "            sentences +=Make_sentences(essay, remove_stopwords = True)\n",
    "        \n",
    "        #Initializing different parameters for the word2vec model to be used\n",
    "    \n",
    "        num_features = 300\n",
    "        min_word_count = 40\n",
    "        num_workers = 4\n",
    "        context = 10\n",
    "        downsampling = 1e-3\n",
    "\n",
    "        print(\"Training Word2Vec Model...\")\n",
    "        \n",
    "        #Initializing model fro vectorization\n",
    "        \n",
    "    \n",
    "        #initializing model and loading parameters\n",
    "    \n",
    "        model = Word2Vec(sentences,vector_size=300, workers=num_workers, min_count = min_word_count, window = context)\n",
    "        #avoiding normalization to not reduce the essence of some words used in context\n",
    "    \n",
    "        model.init_sims(replace=False)\n",
    "    \n",
    "        #saving model\n",
    "    \n",
    "        model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "        \n",
    "        print(\"--------------- Traning complete-------------------\")\n",
    "        \n",
    "        print(\"--------------- Initializing vectorization on train set -------------------\")\n",
    "        \n",
    "        \n",
    "        #generating vectors train\n",
    "    \n",
    "        clean_train = []\n",
    "        for essay in trainE:\n",
    "            clean_train.append(wordlist(essay, remove_stopwords=True))\n",
    "        trainDataVecs = getAvgFeatureVecs(clean_train, model, num_features)\n",
    "    \n",
    "        print(\"--------------completed-----------------\")\n",
    "    \n",
    "        print(\"--------------- Initializing vectorization on test set -------------------\")\n",
    "        \n",
    "        #generating vectors for test\n",
    "    \n",
    "        clean_test = []\n",
    "        for essay in testE:\n",
    "            clean_test.append(wordlist(essay, remove_stopwords=True))\n",
    "        testDataVecs = getAvgFeatureVecs(clean_test, model, num_features)\n",
    "        \n",
    "        trainDataVecs = np.array(trainDataVecs)\n",
    "        testDataVecs = np.array(testDataVecs)\n",
    "        \n",
    "        print(\"------------Complete----------------------\") \n",
    "        \n",
    "        print(\"------------Adding extra dimension to essay----------------------\") \n",
    "        \n",
    "        #Adding extra dimension to essay\n",
    "        \n",
    "        trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "        \n",
    "        testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "        \n",
    "        print(\"------------Complete----------------------\") \n",
    "        \n",
    "        print(\"------------Traning the Preprocessed Data----------------------\") \n",
    "        \n",
    "        #Traning the Preprocessed Data\n",
    "        \n",
    "        lstm_model = get_model()\n",
    "        \n",
    "        print('-----------Complete--------------')\n",
    "        \n",
    "        print('------------------fitting data----------------------')\n",
    "        \n",
    "        #fitting dataset\n",
    "        checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "        history=lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50,callbacks=[checkpoint],validation_split=0.1)\n",
    "        \n",
    "        print('-----------Complete--------------')\n",
    "        \n",
    "        print('---------------Predicting test set------------------------')\n",
    "        \n",
    "        #predicting test\n",
    "        \n",
    "        y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "        # Save any one of the 8 models.\n",
    "        \n",
    "        if count == 5:\n",
    "             lstm_model.save('./final_lstm.h5')\n",
    "            \n",
    "        # Round y_pred to the nearest integer.\n",
    "        y_pred = np.around(y_pred)\n",
    "    \n",
    "            # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "        result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "        print(\"Kappa Score: {}\".format(result))\n",
    "        results.append(result)\n",
    "\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
