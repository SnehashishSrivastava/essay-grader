{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR='Dataset and discription/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(columns=['rater1_domain1','rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  \n",
       "0                  8  \n",
       "1                  9  \n",
       "2                  7  \n",
       "3                 10  \n",
       "4                  8  \n",
       "...              ...  \n",
       "12971             35  \n",
       "12972             32  \n",
       "12973             40  \n",
       "12974             40  \n",
       "12975             40  \n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=X['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = np.array([-1, 2, 1, 0, 0, 0, 0, 0, 0])\n",
    "maximum_scores = np.array([-1, 12, 6, 3, 3, 4, 4, 30, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  score  \n",
       "0                  8    6.0  \n",
       "1                  9    7.0  \n",
       "2                  7    5.0  \n",
       "3                 10    8.0  \n",
       "4                  8    6.0  \n",
       "...              ...    ...  \n",
       "12971             35    6.0  \n",
       "12972             32    5.0  \n",
       "12973             40    7.0  \n",
       "12974             40    7.0  \n",
       "12975             40    7.0  \n",
       "\n",
       "[12976 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_min = minimum_scores[X['essay_set']]\n",
    "old_max = maximum_scores[X['essay_set']]\n",
    "old_range = old_max - old_min \n",
    "new_range = (10 - 0)  \n",
    "X['score'] = np.around((((X['domain1_score'] - old_min) * new_range) / old_range) )\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "def wordlist(essay, remove_stopwords):\n",
    "    \n",
    "    essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
    "    words = essay.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_sentences(essay, remove_stopwords):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    \n",
    "    featureVec = np.zeros((num_features),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_config\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.3, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.3))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /home/shreyash/anaconda3/lib/python3.7/site-packages (4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/shreyash/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/shreyash/anaconda3/lib/python3.7/site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/shreyash/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/home/shreyash/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 13.3726 - accuracy: 0.1257WARNING:tensorflow:From /home/shreyash/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/shreyash/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model-001.model/assets\n",
      "146/146 [==============================] - 7s 50ms/step - loss: 13.1902 - accuracy: 0.1265 - val_loss: 504.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 4.8330 - accuracy: 0.1481INFO:tensorflow:Assets written to: model-002.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 4.8274 - accuracy: 0.1484 - val_loss: 412.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 3.7234 - accuracy: 0.1485INFO:tensorflow:Assets written to: model-003.model/assets\n",
      "146/146 [==============================] - 7s 47ms/step - loss: 3.7219 - accuracy: 0.1481 - val_loss: 400.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 3.3922 - accuracy: 0.1472INFO:tensorflow:Assets written to: model-004.model/assets\n",
      "146/146 [==============================] - 7s 46ms/step - loss: 3.3830 - accuracy: 0.1476 - val_loss: 369.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 3.1500 - accuracy: 0.1470INFO:tensorflow:Assets written to: model-005.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 3.1405 - accuracy: 0.1473 - val_loss: 339.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.9682 - accuracy: 0.1480 - val_loss: 354.3129 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.8749 - accuracy: 0.1477 - val_loss: 367.9214 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.6719 - accuracy: 0.1477INFO:tensorflow:Assets written to: model-008.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 2.6719 - accuracy: 0.1477 - val_loss: 327.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.5928 - accuracy: 0.1487INFO:tensorflow:Assets written to: model-009.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 2.5928 - accuracy: 0.1487 - val_loss: 309.2328 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.3756 - accuracy: 0.1498 - val_loss: 312.8050 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.3558 - accuracy: 0.1481 - val_loss: 350.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.2955 - accuracy: 0.1496INFO:tensorflow:Assets written to: model-012.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 2.2955 - accuracy: 0.1496 - val_loss: 308.0786 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.2267 - accuracy: 0.1489INFO:tensorflow:Assets written to: model-013.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 2.2267 - accuracy: 0.1489 - val_loss: 299.6708 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 2.1982 - accuracy: 0.1493INFO:tensorflow:Assets written to: model-014.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 2.2044 - accuracy: 0.1495 - val_loss: 297.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.1243 - accuracy: 0.1510 - val_loss: 309.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 2.0306 - accuracy: 0.1518INFO:tensorflow:Assets written to: model-016.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 2.0315 - accuracy: 0.1517 - val_loss: 289.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9775 - accuracy: 0.1517 - val_loss: 299.8029 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0682 - accuracy: 0.1515 - val_loss: 298.1058 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.0160 - accuracy: 0.1517INFO:tensorflow:Assets written to: model-019.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.0078 - accuracy: 0.1521 - val_loss: 289.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.0078 - accuracy: 0.1519INFO:tensorflow:Assets written to: model-020.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.0014 - accuracy: 0.1515 - val_loss: 289.5841 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9696 - accuracy: 0.1521 - val_loss: 305.2918 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9330 - accuracy: 0.1516 - val_loss: 293.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8909 - accuracy: 0.1521 - val_loss: 296.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9207 - accuracy: 0.1524 - val_loss: 327.2274 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 1.8629 - accuracy: 0.1519INFO:tensorflow:Assets written to: model-025.model/assets\n",
      "146/146 [==============================] - 6s 39ms/step - loss: 1.8594 - accuracy: 0.1523 - val_loss: 260.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7993 - accuracy: 0.1520 - val_loss: 293.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8242 - accuracy: 0.1521 - val_loss: 283.6415 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8068 - accuracy: 0.1526 - val_loss: 283.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7438 - accuracy: 0.1530 - val_loss: 288.1712 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7004 - accuracy: 0.1518 - val_loss: 271.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6735 - accuracy: 0.1522 - val_loss: 276.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6910 - accuracy: 0.1530 - val_loss: 268.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6985 - accuracy: 0.1525 - val_loss: 286.9368 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7600 - accuracy: 0.1529 - val_loss: 275.8026 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6517 - accuracy: 0.1523 - val_loss: 288.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6509 - accuracy: 0.1516 - val_loss: 283.5872 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6536 - accuracy: 0.1536 - val_loss: 289.3489 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6582 - accuracy: 0.1516 - val_loss: 285.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6830 - accuracy: 0.1521 - val_loss: 295.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.5948 - accuracy: 0.1531 - val_loss: 288.8151 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7152988553741446\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 13.3758 - accuracy: 0.1295INFO:tensorflow:Assets written to: model-001.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 13.3182 - accuracy: 0.1295 - val_loss: 506.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 4.8193 - accuracy: 0.1493INFO:tensorflow:Assets written to: model-002.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 4.7919 - accuracy: 0.1488 - val_loss: 434.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 3.5544 - accuracy: 0.1483INFO:tensorflow:Assets written to: model-003.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 3.5830 - accuracy: 0.1484 - val_loss: 405.7189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 3.1883 - accuracy: 0.1484INFO:tensorflow:Assets written to: model-004.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 3.1883 - accuracy: 0.1484 - val_loss: 373.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 3.0308 - accuracy: 0.1470INFO:tensorflow:Assets written to: model-005.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 3.0560 - accuracy: 0.1468 - val_loss: 344.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.7581 - accuracy: 0.1477INFO:tensorflow:Assets written to: model-006.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.7581 - accuracy: 0.1477 - val_loss: 338.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.6189 - accuracy: 0.1498INFO:tensorflow:Assets written to: model-007.model/assets\n",
      "146/146 [==============================] - 6s 39ms/step - loss: 2.6189 - accuracy: 0.1498 - val_loss: 326.8904 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.5442 - accuracy: 0.1501 - val_loss: 342.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.3826 - accuracy: 0.1494INFO:tensorflow:Assets written to: model-009.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.3826 - accuracy: 0.1494 - val_loss: 314.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.4244 - accuracy: 0.1491INFO:tensorflow:Assets written to: model-010.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.4138 - accuracy: 0.1492 - val_loss: 308.3729 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.2625 - accuracy: 0.1513INFO:tensorflow:Assets written to: model-011.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 2.2625 - accuracy: 0.1513 - val_loss: 300.9654 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 2.2547 - accuracy: 0.1503INFO:tensorflow:Assets written to: model-012.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 2.2516 - accuracy: 0.1500 - val_loss: 292.8996 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.1291 - accuracy: 0.1521 - val_loss: 293.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 2.0969 - accuracy: 0.1517INFO:tensorflow:Assets written to: model-014.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.0947 - accuracy: 0.1520 - val_loss: 287.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0621 - accuracy: 0.1525 - val_loss: 300.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0857 - accuracy: 0.1533 - val_loss: 288.0985 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0469 - accuracy: 0.1522 - val_loss: 296.5699 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.0532 - accuracy: 0.1539 - val_loss: 287.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 1.9745 - accuracy: 0.1536INFO:tensorflow:Assets written to: model-019.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 1.9688 - accuracy: 0.1536 - val_loss: 284.8454 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 2.0017 - accuracy: 0.1535INFO:tensorflow:Assets written to: model-020.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 2.0253 - accuracy: 0.1539 - val_loss: 275.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 1.9554 - accuracy: 0.1537INFO:tensorflow:Assets written to: model-021.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 1.9515 - accuracy: 0.1536 - val_loss: 266.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8906 - accuracy: 0.1542 - val_loss: 294.6202 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8606 - accuracy: 0.1551 - val_loss: 278.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8655 - accuracy: 0.1541 - val_loss: 274.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8839 - accuracy: 0.1549 - val_loss: 286.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7551 - accuracy: 0.1550 - val_loss: 275.1652 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8151 - accuracy: 0.1545 - val_loss: 268.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7807 - accuracy: 0.1553 - val_loss: 270.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8013 - accuracy: 0.1552 - val_loss: 276.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7340 - accuracy: 0.1545 - val_loss: 270.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6565 - accuracy: 0.1555 - val_loss: 281.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7605 - accuracy: 0.1547 - val_loss: 268.6439 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7296 - accuracy: 0.1552 - val_loss: 266.6330 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6311 - accuracy: 0.1541 - val_loss: 274.1408 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 1.6188 - accuracy: 0.1559INFO:tensorflow:Assets written to: model-035.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 1.6211 - accuracy: 0.1553 - val_loss: 264.3564 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7071 - accuracy: 0.1550 - val_loss: 268.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6785 - accuracy: 0.1550 - val_loss: 288.3773 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6554 - accuracy: 0.1562 - val_loss: 277.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.5936 - accuracy: 0.1544 - val_loss: 271.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.5190 - accuracy: 0.1557 - val_loss: 268.4971 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7751232227023079\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 12.5211 - accuracy: 0.1323INFO:tensorflow:Assets written to: model-001.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 12.4430 - accuracy: 0.1325 - val_loss: 467.8058 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 4.5889 - accuracy: 0.1485INFO:tensorflow:Assets written to: model-002.model/assets\n",
      "146/146 [==============================] - 6s 38ms/step - loss: 4.5567 - accuracy: 0.1486 - val_loss: 392.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 3.5225 - accuracy: 0.1480 - val_loss: 394.9730 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 3.2073 - accuracy: 0.1478INFO:tensorflow:Assets written to: model-004.model/assets\n",
      "146/146 [==============================] - 7s 48ms/step - loss: 3.1981 - accuracy: 0.1481 - val_loss: 340.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.9543 - accuracy: 0.1473 - val_loss: 359.1121 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 2.7857 - accuracy: 0.1471 - val_loss: 346.6976 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.6879 - accuracy: 0.1489 - val_loss: 342.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 2.6262 - accuracy: 0.1504INFO:tensorflow:Assets written to: model-008.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 2.6277 - accuracy: 0.1500 - val_loss: 314.3908 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.4291 - accuracy: 0.1503INFO:tensorflow:Assets written to: model-009.model/assets\n",
      "146/146 [==============================] - 5s 37ms/step - loss: 2.4291 - accuracy: 0.1503 - val_loss: 312.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.3746 - accuracy: 0.1503 - val_loss: 326.7796 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.3080 - accuracy: 0.1504INFO:tensorflow:Assets written to: model-011.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 2.3202 - accuracy: 0.1504 - val_loss: 301.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.1507 - accuracy: 0.1528INFO:tensorflow:Assets written to: model-012.model/assets\n",
      "146/146 [==============================] - 6s 39ms/step - loss: 2.1507 - accuracy: 0.1528 - val_loss: 290.6077 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.1969 - accuracy: 0.1520 - val_loss: 304.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - ETA: 0s - loss: 2.1226 - accuracy: 0.1518INFO:tensorflow:Assets written to: model-014.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 2.1226 - accuracy: 0.1518 - val_loss: 288.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.1211 - accuracy: 0.1524 - val_loss: 302.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.0941 - accuracy: 0.1531INFO:tensorflow:Assets written to: model-016.model/assets\n",
      "146/146 [==============================] - 5s 36ms/step - loss: 2.0941 - accuracy: 0.1531 - val_loss: 278.3938 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.0317 - accuracy: 0.1539 - val_loss: 282.9497 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.0065 - accuracy: 0.1526INFO:tensorflow:Assets written to: model-018.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 2.0065 - accuracy: 0.1526 - val_loss: 271.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9648 - accuracy: 0.1536 - val_loss: 304.0292 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8756 - accuracy: 0.1528 - val_loss: 312.6501 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.9953 - accuracy: 0.1531 - val_loss: 276.9946 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 1.9431 - accuracy: 0.1519INFO:tensorflow:Assets written to: model-022.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 1.9352 - accuracy: 0.1519 - val_loss: 256.9836 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8947 - accuracy: 0.1533 - val_loss: 268.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9214 - accuracy: 0.1540 - val_loss: 267.6894 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8337 - accuracy: 0.1539 - val_loss: 290.0858 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.8017 - accuracy: 0.1547 - val_loss: 273.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8256 - accuracy: 0.1533 - val_loss: 277.0897 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7756 - accuracy: 0.1548 - val_loss: 287.6028 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.7359 - accuracy: 0.1540 - val_loss: 286.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.7695 - accuracy: 0.1544 - val_loss: 287.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6745 - accuracy: 0.1561 - val_loss: 267.2293 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7017 - accuracy: 0.1545 - val_loss: 257.3090 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7111 - accuracy: 0.1555 - val_loss: 292.1516 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6619 - accuracy: 0.1546 - val_loss: 272.2838 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6810 - accuracy: 0.1549 - val_loss: 290.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6848 - accuracy: 0.1555 - val_loss: 266.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6743 - accuracy: 0.1554 - val_loss: 263.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7165 - accuracy: 0.1563 - val_loss: 280.2953 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.5857 - accuracy: 0.1553 - val_loss: 272.5738 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.5579 - accuracy: 0.1569 - val_loss: 276.9728 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7281912259822548\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 12.7774 - accuracy: 0.1287INFO:tensorflow:Assets written to: model-001.model/assets\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 12.6974 - accuracy: 0.1289 - val_loss: 503.3727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 4.7446 - accuracy: 0.1488INFO:tensorflow:Assets written to: model-002.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 4.7302 - accuracy: 0.1489 - val_loss: 419.4138 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 3.5834 - accuracy: 0.1488INFO:tensorflow:Assets written to: model-003.model/assets\n",
      "146/146 [==============================] - 7s 48ms/step - loss: 3.5834 - accuracy: 0.1488 - val_loss: 389.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 3.1705 - accuracy: 0.1488 - val_loss: 416.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 3.1079 - accuracy: 0.1478INFO:tensorflow:Assets written to: model-005.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 3.1079 - accuracy: 0.1478 - val_loss: 362.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.9024 - accuracy: 0.1488INFO:tensorflow:Assets written to: model-006.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 2.9024 - accuracy: 0.1488 - val_loss: 345.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.7107 - accuracy: 0.1492 - val_loss: 351.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 2.6070 - accuracy: 0.1488INFO:tensorflow:Assets written to: model-008.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 2.5879 - accuracy: 0.1495 - val_loss: 336.8573 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 2.5070 - accuracy: 0.1484INFO:tensorflow:Assets written to: model-009.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 2.5039 - accuracy: 0.1483 - val_loss: 323.9940 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1481INFO:tensorflow:Assets written to: model-010.model/assets\n",
      "146/146 [==============================] - 8s 56ms/step - loss: 2.2968 - accuracy: 0.1485 - val_loss: 314.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.3185 - accuracy: 0.1489 - val_loss: 370.8054 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 2.2387 - accuracy: 0.1494 - val_loss: 343.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "145/146 [============================>.] - ETA: 0s - loss: 2.1754 - accuracy: 0.1495INFO:tensorflow:Assets written to: model-013.model/assets\n",
      "146/146 [==============================] - 8s 52ms/step - loss: 2.1660 - accuracy: 0.1498 - val_loss: 299.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.1880 - accuracy: 0.1511INFO:tensorflow:Assets written to: model-014.model/assets\n",
      "146/146 [==============================] - 7s 51ms/step - loss: 2.1880 - accuracy: 0.1511 - val_loss: 297.8266 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.1164 - accuracy: 0.1514 - val_loss: 299.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 2.0572 - accuracy: 0.1515 - val_loss: 298.7429 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 1.9902 - accuracy: 0.1525INFO:tensorflow:Assets written to: model-017.model/assets\n",
      "146/146 [==============================] - 5s 37ms/step - loss: 1.9902 - accuracy: 0.1525 - val_loss: 297.3382 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.9692 - accuracy: 0.1532 - val_loss: 313.9540 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9366 - accuracy: 0.1521 - val_loss: 301.6061 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9985 - accuracy: 0.1531 - val_loss: 311.0519 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 1.9020 - accuracy: 0.1537INFO:tensorflow:Assets written to: model-021.model/assets\n",
      "146/146 [==============================] - 8s 57ms/step - loss: 1.9154 - accuracy: 0.1523 - val_loss: 296.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.9152 - accuracy: 0.1533 - val_loss: 307.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 1.8620 - accuracy: 0.1541INFO:tensorflow:Assets written to: model-023.model/assets\n",
      "146/146 [==============================] - 6s 42ms/step - loss: 1.8564 - accuracy: 0.1537 - val_loss: 287.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 1.8647 - accuracy: 0.1536INFO:tensorflow:Assets written to: model-024.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 1.8647 - accuracy: 0.1536 - val_loss: 268.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8078 - accuracy: 0.1544 - val_loss: 275.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7777 - accuracy: 0.1546 - val_loss: 289.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7821 - accuracy: 0.1546 - val_loss: 311.2939 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8334 - accuracy: 0.1531 - val_loss: 280.5722 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.8032 - accuracy: 0.1542 - val_loss: 295.5950 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7502 - accuracy: 0.1535 - val_loss: 292.8285 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6653 - accuracy: 0.1539 - val_loss: 297.3551 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7580 - accuracy: 0.1544 - val_loss: 280.7634 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7313 - accuracy: 0.1553 - val_loss: 292.2323 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.7048 - accuracy: 0.1545 - val_loss: 284.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6396 - accuracy: 0.1546 - val_loss: 305.3595 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6324 - accuracy: 0.1559 - val_loss: 287.6235 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6251 - accuracy: 0.1550 - val_loss: 290.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.5990 - accuracy: 0.1540 - val_loss: 315.7938 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.5660 - accuracy: 0.1549 - val_loss: 283.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "146/146 [==============================] - 2s 11ms/step - loss: 1.6010 - accuracy: 0.1544 - val_loss: 298.6241 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7319408434147223\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "--------------- Traning complete-------------------\n",
      "--------------- Initializing vectorization on train set -------------------\n",
      "--------------completed-----------------\n",
      "--------------- Initializing vectorization on test set -------------------\n",
      "------------Complete----------------------\n",
      "------------Adding extra dimension to essay----------------------\n",
      "------------Complete----------------------\n",
      "------------Traning the Preprocessed Data----------------------\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-----------Complete--------------\n",
      "------------------fitting data----------------------\n",
      "Epoch 1/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 12.4472 - accuracy: 0.1287INFO:tensorflow:Assets written to: model-001.model/assets\n",
      "146/146 [==============================] - 7s 48ms/step - loss: 12.3552 - accuracy: 0.1298 - val_loss: 491.8410 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 4.6460 - accuracy: 0.1482INFO:tensorflow:Assets written to: model-002.model/assets\n",
      "146/146 [==============================] - 6s 39ms/step - loss: 4.6147 - accuracy: 0.1484 - val_loss: 421.3820 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/146 [============================>.] - ETA: 0s - loss: 3.5186 - accuracy: 0.1490INFO:tensorflow:Assets written to: model-003.model/assets\n",
      "146/146 [==============================] - 7s 46ms/step - loss: 3.5321 - accuracy: 0.1489 - val_loss: 375.2642 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 3.2743 - accuracy: 0.1483 - val_loss: 375.6187 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 3.0296 - accuracy: 0.1490INFO:tensorflow:Assets written to: model-005.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 3.0162 - accuracy: 0.1485 - val_loss: 362.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 2.9479 - accuracy: 0.1479INFO:tensorflow:Assets written to: model-006.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.9389 - accuracy: 0.1464 - val_loss: 356.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.8176 - accuracy: 0.1480INFO:tensorflow:Assets written to: model-007.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.8106 - accuracy: 0.1481 - val_loss: 352.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.6109 - accuracy: 0.1483INFO:tensorflow:Assets written to: model-008.model/assets\n",
      "146/146 [==============================] - 6s 41ms/step - loss: 2.6109 - accuracy: 0.1483 - val_loss: 348.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 2.5099 - accuracy: 0.1473INFO:tensorflow:Assets written to: model-009.model/assets\n",
      "146/146 [==============================] - 6s 43ms/step - loss: 2.4994 - accuracy: 0.1484 - val_loss: 318.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.2935 - accuracy: 0.1501 - val_loss: 334.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 2.1834 - accuracy: 0.1501INFO:tensorflow:Assets written to: model-011.model/assets\n",
      "146/146 [==============================] - 7s 47ms/step - loss: 2.1834 - accuracy: 0.1501 - val_loss: 299.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 2.2902 - accuracy: 0.1493 - val_loss: 299.9941 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "144/146 [============================>.] - ETA: 0s - loss: 2.1859 - accuracy: 0.1490INFO:tensorflow:Assets written to: model-013.model/assets\n",
      "146/146 [==============================] - 7s 50ms/step - loss: 2.1754 - accuracy: 0.1491 - val_loss: 295.2336 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 2.1086 - accuracy: 0.1500 - val_loss: 310.5826 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.0507 - accuracy: 0.1492 - val_loss: 304.8797 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 1.9998 - accuracy: 0.1498INFO:tensorflow:Assets written to: model-016.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 1.9964 - accuracy: 0.1499 - val_loss: 274.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 2.0253 - accuracy: 0.1501 - val_loss: 310.8879 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 1.9649 - accuracy: 0.1501INFO:tensorflow:Assets written to: model-018.model/assets\n",
      "146/146 [==============================] - 7s 45ms/step - loss: 1.9597 - accuracy: 0.1504 - val_loss: 270.8152 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "142/146 [============================>.] - ETA: 0s - loss: 1.9278 - accuracy: 0.1496INFO:tensorflow:Assets written to: model-019.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 1.9275 - accuracy: 0.1499 - val_loss: 264.5941 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.9381 - accuracy: 0.1504 - val_loss: 277.2830 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.8245 - accuracy: 0.1502 - val_loss: 280.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7495 - accuracy: 0.1501 - val_loss: 283.4034 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "143/146 [============================>.] - ETA: 0s - loss: 1.8181 - accuracy: 0.1505INFO:tensorflow:Assets written to: model-023.model/assets\n",
      "146/146 [==============================] - 6s 40ms/step - loss: 1.8122 - accuracy: 0.1510 - val_loss: 250.0370 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7679 - accuracy: 0.1528 - val_loss: 269.9750 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.7477 - accuracy: 0.1508 - val_loss: 255.4693 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7824 - accuracy: 0.1519 - val_loss: 252.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7833 - accuracy: 0.1515 - val_loss: 270.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7024 - accuracy: 0.1515 - val_loss: 264.2630 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6935 - accuracy: 0.1515 - val_loss: 271.3087 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.7583 - accuracy: 0.1520 - val_loss: 260.3886 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6682 - accuracy: 0.1518 - val_loss: 258.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6942 - accuracy: 0.1520 - val_loss: 277.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "146/146 [==============================] - ETA: 0s - loss: 1.7187 - accuracy: 0.1518INFO:tensorflow:Assets written to: model-033.model/assets\n",
      "146/146 [==============================] - 6s 44ms/step - loss: 1.7187 - accuracy: 0.1518 - val_loss: 248.3796 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.7267 - accuracy: 0.1521 - val_loss: 272.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6316 - accuracy: 0.1521 - val_loss: 283.7986 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "146/146 [==============================] - 2s 12ms/step - loss: 1.6487 - accuracy: 0.1525 - val_loss: 254.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6647 - accuracy: 0.1521 - val_loss: 270.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "146/146 [==============================] - 2s 13ms/step - loss: 1.6349 - accuracy: 0.1521 - val_loss: 264.4006 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 1.5975 - accuracy: 0.1532 - val_loss: 261.6554 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "146/146 [==============================] - 2s 14ms/step - loss: 1.5914 - accuracy: 0.1526 - val_loss: 256.6716 - val_accuracy: 0.0000e+00\n",
      "-----------Complete--------------\n",
      "---------------Predicting test set------------------------\n",
      "Kappa Score: 0.7616153152307928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "count=1\n",
    "results=[]\n",
    "for train,test in skf.split(X,Y):\n",
    "        print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "        X_test, X_train, y_test, y_train = X.iloc[test], X.iloc[train], Y.iloc[test], Y.iloc[train]\n",
    "        trainE = X_train['essay']\n",
    "        testE= X_test['essay']\n",
    "        sentences=[]\n",
    "        for essay in trainE:\n",
    "        # Obtaining all sentences from the training essays.\n",
    "        \n",
    "            sentences +=Make_sentences(essay, remove_stopwords = True)\n",
    "        \n",
    "        #Initializing different parameters for the word2vec model to be used\n",
    "    \n",
    "        num_features = 300\n",
    "        min_word_count = 40\n",
    "        num_workers = 4\n",
    "        context = 10\n",
    "        downsampling = 1e-3\n",
    "\n",
    "        print(\"Training Word2Vec Model...\")\n",
    "        \n",
    "        #Initializing model fro vectorization\n",
    "        \n",
    "    \n",
    "        #initializing model and loading parameters\n",
    "    \n",
    "        model = Word2Vec(sentences,vector_size=300, workers=num_workers, min_count = min_word_count, window = context)\n",
    "        #avoiding normalization to not reduce the essence of some words used in context\n",
    "    \n",
    "        model.init_sims(replace=False)\n",
    "    \n",
    "        #saving model\n",
    "    \n",
    "        model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "        \n",
    "        print(\"--------------- Traning complete-------------------\")\n",
    "        \n",
    "        print(\"--------------- Initializing vectorization on train set -------------------\")\n",
    "        \n",
    "        \n",
    "        #generating vectors train\n",
    "    \n",
    "        clean_train = []\n",
    "        for essay in trainE:\n",
    "            clean_train.append(wordlist(essay, remove_stopwords=True))\n",
    "        trainDataVecs = getAvgFeatureVecs(clean_train, model, num_features)\n",
    "    \n",
    "        print(\"--------------completed-----------------\")\n",
    "    \n",
    "        print(\"--------------- Initializing vectorization on test set -------------------\")\n",
    "        \n",
    "        #generating vectors for test\n",
    "    \n",
    "        clean_test = []\n",
    "        for essay in testE:\n",
    "            clean_test.append(wordlist(essay, remove_stopwords=True))\n",
    "        testDataVecs = getAvgFeatureVecs(clean_test, model, num_features)\n",
    "        \n",
    "        trainDataVecs = np.array(trainDataVecs)\n",
    "        testDataVecs = np.array(testDataVecs)\n",
    "        \n",
    "        print(\"------------Complete----------------------\") \n",
    "        \n",
    "        print(\"------------Adding extra dimension to essay----------------------\") \n",
    "        \n",
    "        #Adding extra dimension to essay\n",
    "        \n",
    "        trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "        \n",
    "        testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "        \n",
    "        print(\"------------Complete----------------------\") \n",
    "        \n",
    "        print(\"------------Traning the Preprocessed Data----------------------\") \n",
    "        \n",
    "        #Traning the Preprocessed Data\n",
    "        \n",
    "        lstm_model = get_model()\n",
    "        \n",
    "        print('-----------Complete--------------')\n",
    "        \n",
    "        print('------------------fitting data----------------------')\n",
    "        \n",
    "        #fitting dataset\n",
    "        checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "        history=lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=40,callbacks=[checkpoint],validation_split=0.1)\n",
    "        \n",
    "        print('-----------Complete--------------')\n",
    "        \n",
    "        print('---------------Predicting test set------------------------')\n",
    "        \n",
    "        #predicting test\n",
    "        \n",
    "        y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "        # Save any one of the 8 models.\n",
    "        \n",
    "        if count == 5:\n",
    "             lstm_model.save('./final_lstm.h5')\n",
    "            \n",
    "        # Round y_pred to the nearest integer.\n",
    "        y_pred = np.around(y_pred)\n",
    "    \n",
    "            # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "        result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "        print(\"Kappa Score: {}\".format(result))\n",
    "        results.append(result)\n",
    "\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
